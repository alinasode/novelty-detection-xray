{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import axis, colorbar, imshow, show, figure, subplot\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "mpl.rc('axes', labelsize=18)\n",
    "mpl.rc('xtick', labelsize=16)\n",
    "mpl.rc('ytick', labelsize=16)\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## ----- GPU ------------------------------------\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'    # use of GPU 0 (ERDA) (use before importing torch or tensorflow/keeas)\n",
    "## ----------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n",
    "from keras.layers import BatchNormalization, ReLU, LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.losses import binary_crossentropy, mse\n",
    "from keras.activations import relu\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K                         #contains calls for tensor manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "2.4.3\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL_TRAIN_AUG:       /home/jovyan/work/Speciale/FoodSorting/generated_dataset/Potato//DataAugmentation/NormalTrainAugmentations\n",
      "NORMAL_VALIDATION_AUG:  /home/jovyan/work/Speciale/FoodSorting/generated_dataset/Potato//DataAugmentation/NormalValidationAugmentations\n",
      "NORMAL_TEST_AUG:        /home/jovyan/work/Speciale/FoodSorting/generated_dataset/Potato//DataAugmentation/NormalTestAugmentations\n",
      "ANOMALY1_AUG:           /home/jovyan/work/Speciale/FoodSorting/generated_dataset/Potato//DataAugmentation/Anomaly1Augmentations\n",
      "ANOMALY2_AUG:           /home/jovyan/work/Speciale/FoodSorting/generated_dataset/Potato//DataAugmentation/Anomaly2Augmentations\n"
     ]
    }
   ],
   "source": [
    "from utils_ae_potato_paths import *\n",
    "\n",
    "# Get work directions for augmentated data set:\n",
    "print (\"NORMAL_TRAIN_AUG:      \", NORMAL_TRAIN_AUG)\n",
    "print (\"NORMAL_VALIDATION_AUG: \", NORMAL_VAL_AUG)\n",
    "print (\"NORMAL_TEST_AUG:       \", NORMAL_TEST_AUG)\n",
    "print (\"ANOMALY1_AUG:          \", ANOMALY1_AUG)\n",
    "print (\"ANOMALY2_AUG:          \", ANOMALY2_AUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Folder The Models Are Saved In: saved_models/latent16\n"
     ]
    }
   ],
   "source": [
    "# What latent dimension and filter size are we using?:\n",
    "latent_dim = 16\n",
    "filters    = 32\n",
    "\n",
    "# Get work direction for saving files:\n",
    "SAVE_FOLDER = f'saved_models/latent{latent_dim}'\n",
    "print (\"Which Folder The Models Are Saved In:\", SAVE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] deleting existing files in folder...\n",
      "         done in 0.004 minutes\n"
     ]
    }
   ],
   "source": [
    "# Delete all existing files in folder where models are saved:\n",
    "print(\"[INFO] deleting existing files in folder...\")\n",
    "t0 = time()\n",
    "\n",
    "files = glob.glob(f'{SAVE_FOLDER}/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "print (\"         done in %0.3f minutes\" % ((time() - t0)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_VAE_AE import get_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Investigation of Ground Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"normal\" training images is:     1639\n",
      "Number of \"normal\" validation images is:   80\n",
      "Number of \"normal\" test images is:         320\n",
      "Total number of \"anomaly\" images is:       680\n"
     ]
    }
   ],
   "source": [
    "# Glob the directories and get the lists of good and bad images\n",
    "good_train_fns = [f for f in os.listdir(NORMAL_TRAIN_AUG) if not f.startswith('.')]\n",
    "good_val_fns = [f for f in os.listdir(NORMAL_VAL_AUG) if not f.startswith('.')]\n",
    "good_test_fns = [f for f in os.listdir(NORMAL_TEST_AUG) if not f.startswith('.')]\n",
    "bad1_fns = [f for f in os.listdir(ANOMALY1_AUG) if not f.startswith('.')]\n",
    "bad2_fns = [f for f in os.listdir(ANOMALY2_AUG) if not f.startswith('.')]\n",
    "\n",
    "print('Number of \"normal\" training images is:     {}'.format(len(good_train_fns)))\n",
    "print('Number of \"normal\" validation images is:   {}'.format(len(good_val_fns)))\n",
    "print('Number of \"normal\" test images is:         {}'.format(len(good_test_fns)))\n",
    "print('Total number of \"anomaly\" images is:       {}'.format(len(bad1_fns) + len(bad2_fns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Procentage of normal samples (ground truth):   74.99 %\n",
      "> Procentage of anomaly samples (ground truth):  25.01 %\n"
     ]
    }
   ],
   "source": [
    "# compute procentage of bad images vs good images:\n",
    "normal_fns = len(good_train_fns) + len(good_val_fns) + len(good_test_fns)\n",
    "anomaly_fns = len(bad1_fns + bad2_fns)\n",
    "print(f\"> Procentage of normal samples (ground truth):   {(normal_fns / (normal_fns + anomaly_fns)) * 100:.2f} %\")\n",
    "print(f\"> Procentage of anomaly samples (ground truth):  {(anomaly_fns / (normal_fns + anomaly_fns)) * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Normal Data\n",
    "\n",
    "Load normal samples in pre-splitted data sets: train, valdiation and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading normal training images...\n",
      "          done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading normal training images...\")\n",
    "trainX = [cv2.imread(file, 0) for file in glob.glob(f\"{NORMAL_TRAIN_AUG}/*.png\")]  # read as grayscale\n",
    "trainX = np.array(trainX)\n",
    "print(\"          done\")\n",
    "\n",
    "# create a corresponding list of labels:\n",
    "trainY = get_labels(trainX, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading normal validation images...\n",
      "          done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading normal validation images...\")\n",
    "x_normal_val = [cv2.imread(file, 0) for file in glob.glob(f\"{NORMAL_VAL_AUG}/*.png\")]  # read as grayscale\n",
    "x_normal_val = np.array(x_normal_val)\n",
    "print(\"          done\")\n",
    "\n",
    "# create a corresponding list of labels:\n",
    "y_normal_val = get_labels(x_normal_val, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading normal testing images...\n",
      "          done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading normal testing images...\")\n",
    "x_normal_test = [cv2.imread(file, 0) for file in glob.glob(f\"{NORMAL_TEST_AUG}/*.png\")]  # read as grayscale\n",
    "x_normal_test = np.array(x_normal_test)\n",
    "print(\"          done\")\n",
    "\n",
    "# create a corresponding list of labels:\n",
    "y_normal_test = get_labels(x_normal_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Anomaly Class 1 Data (i.e. 'metal' sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading anomaly class 1 ('metal') images...\n",
      "          done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading anomaly class 1 ('metal') images...\")\n",
    "x_metal = [cv2.imread(file, 0) for file in glob.glob(f\"{ANOMALY1_AUG}/*.png\")]  # read as grayscale\n",
    "x_metal = np.array(x_metal)\n",
    "print(\"          done\")\n",
    "\n",
    "# create a corresponding list of labels:\n",
    "y_metal = get_labels(x_metal, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Anomaly Class 2 Data (i.e. 'hollow' sampels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading anomaly class 2 ('hollow') images...\n",
      "          done\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading anomaly class 2 ('hollow') images...\")\n",
    "x_hollow = [cv2.imread(file, 0) for file in glob.glob(f\"{ANOMALY2_AUG}/*.png\")]  # read as grayscale\n",
    "x_hollow = np.array(x_hollow)\n",
    "print(\"          done\")\n",
    "\n",
    "# create a corresponding list of labels:\n",
    "y_hollow = get_labels(x_hollow, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine normal samples and anomaly samples and split them into training, validation and test sets\n",
    "\n",
    "\n",
    "`label 0` == Normal Samples (=> Perfect' Samples)\n",
    "\n",
    "`label 1` == Anomaly 1 Samples (=> 'Metal' Samples)\n",
    "\n",
    "`label 2` == Anomaly 2 Samples (=> 'Hollow' Samples)\n",
    "\n",
    "Train and Validation sets only consists of `Normal Data`, aka. `label 0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine pre-loaded validation and testing set into a new testing set:\n",
    "testvalX = np.vstack((x_normal_val, x_normal_test))\n",
    "testvalY = get_labels(testvalX, 0)\n",
    "\n",
    "# randomly split in order to make new validation set:\n",
    "NoUsageX, valX, NoUsageY, valY = train_test_split(testvalX, testvalY, test_size=0.25, random_state=4345672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Testing set \"\"\"\n",
    "# combine pre-loaded validation and testing set into a new testing set:\n",
    "testNormalX = np.vstack((x_normal_val, x_normal_test))\n",
    "testNormalY = get_labels(testNormalX, 0)\n",
    "\n",
    "# Anomaly Class 1 (i.e. 'metal' samples):\n",
    "testAnomaly1X, testAnomaly1Y = x_metal, y_metal\n",
    "\n",
    "# Anomaly Class 2 (i.e. 'hollow' samples):\n",
    "testAnomaly2X, testAnomaly2Y = x_hollow, y_hollow\n",
    "\n",
    "# Combine all testing data in one array (the test set is NOT used during any part but inference):\n",
    "testAllX = np.vstack((testNormalX, testAnomaly1X, testAnomaly2X))\n",
    "testAllY = np.hstack((testNormalY, testAnomaly1Y, testAnomaly2Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Data Dimensions and Distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect data shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      " > images: (1639, 128, 128)\n",
      " > labels: (1639,)\n",
      "\n",
      "Validation set:\n",
      " > images: (100, 128, 128)\n",
      " > labels: (100,)\n",
      "\n",
      "Test set:\n",
      " > images: (1080, 128, 128)\n",
      " > labels: (1080,)\n",
      "\t'Normal' test set:\n",
      "\t  > images: (400, 128, 128)\n",
      "\t  > labels: (400,)\n",
      "\t'Anomaly 1' test set:\n",
      "\t  > images: (392, 128, 128)\n",
      "\t  > labels: (392,)\n",
      "\t'Anomaly 2' test set:\n",
      "\t  > images: (288, 128, 128)\n",
      "\t  > labels: (288,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "print(\" > images:\", trainX.shape)\n",
    "print(\" > labels:\", trainY.shape)\n",
    "print (\"\")\n",
    "\n",
    "print(\"Validation set:\")\n",
    "print(\" > images:\", valX.shape)\n",
    "print(\" > labels:\", valY.shape)\n",
    "print (\"\")\n",
    "\n",
    "print(\"Test set:\")\n",
    "print(\" > images:\", testAllX.shape)\n",
    "print(\" > labels:\", testAllY.shape)\n",
    "print(\"\\t'Normal' test set:\")\n",
    "print(\"\\t  > images:\", testNormalX.shape)\n",
    "print(\"\\t  > labels:\", testNormalY.shape)\n",
    "print(\"\\t'Anomaly 1' test set:\")\n",
    "print(\"\\t  > images:\", testAnomaly1X.shape)\n",
    "print(\"\\t  > labels:\", testAnomaly1Y.shape)\n",
    "print(\"\\t'Anomaly 2' test set:\")\n",
    "print(\"\\t  > images:\", testAnomaly2X.shape)\n",
    "print(\"\\t  > labels:\", testAnomaly2Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procentage of training samples: 76.62 %\n",
      "Procentage of validation samples: 4.68 %\n",
      "Procentage of (only normal) testing samples: 18.70 %\n"
     ]
    }
   ],
   "source": [
    "# compute procentage between training, validation and test data sets (only normal data):\n",
    "print(f\"Procentage of training samples: {(len(trainX) / (len(trainX) + len(valX) + len(testNormalX))) * 100:.2f} %\")\n",
    "print(f\"Procentage of validation samples: {(len(valX) / (len(trainX) + len(valX) + len(testNormalX))) * 100:.2f} %\")\n",
    "print(f\"Procentage of (only normal) testing samples: {(len(testNormalX) / (len(trainX) + len(valX) + len(testNormalX))) * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procentage of training samples: 58.14 %\n",
      "Procentage of validation samples: 3.55 %\n",
      "Procentage of (total) testing samples: 38.31 %\n"
     ]
    }
   ],
   "source": [
    "# compute procentage between training, validation and test data sets:\n",
    "print(f\"Procentage of training samples: {(len(trainX) / (len(trainX) + len(valX) + len(testAllX))) * 100:.2f} %\")\n",
    "print(f\"Procentage of validation samples: {(len(valX) / (len(trainX) + len(valX) + len(testAllX))) * 100:.2f} %\")\n",
    "print(f\"Procentage of (total) testing samples: {(len(testAllX) / (len(trainX) + len(valX) + len(testAllX))) * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for (un)balanced data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['0: normal', '1: metal', '2: hollow']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16,4))\n",
    "ax[0].hist(trainY, align=\"left\"); ax[0].set_title('train', fontsize=18); ax[0].set_xticks([0,1,2]); ax[0].set_xticklabels(labels); ax[0].tick_params(axis='both', which='major', labelsize=16); ax[0].set_xlim(-0.5, 2.5);\n",
    "ax[1].hist(valY, align=\"left\"); ax[1].set_title('validation', fontsize=18); ax[1].set_xticks([0,1,2]); ax[1].set_xticklabels(labels); ax[1].tick_params(axis='both', which='major', labelsize=16); ax[1].set_xlim(-0.5, 2.5);\n",
    "ax[2].hist(testAllY, align=\"left\"); ax[2].set_title('test', fontsize=18); ax[2].set_xticks([0,1,2]); ax[2].set_xticklabels(labels); ax[2].tick_params(axis='both', which='major', labelsize=16); ax[2].set_xlim(-0.5, 2.5);\n",
    "\n",
    "ax[0].set_ylabel(\"Number of images\", fontsize=18)\n",
    "ax[1].set_xlabel(\"Class Labels\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procentage of normal test samples: 37.04 %\n",
      "Procentage of total anomaly test samples: 62.96 %\n"
     ]
    }
   ],
   "source": [
    "# compute procentage of normal test images vs total anomaly test images:\n",
    "print(f\"Procentage of normal test samples: {(len(testNormalX) / (len(testNormalX) + (len(testAnomaly1X) + len(testAnomaly2X)))) * 100:.2f} %\")\n",
    "print(f\"Procentage of total anomaly test samples: {((len(testAnomaly1X) + len(testAnomaly2X)) / (len(testNormalX) + (len(testAnomaly1X) + len(testAnomaly2X)))) * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Only normalization has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configuration\n",
    "img_width, img_height = trainX.shape[1], trainX.shape[2]      # input image dimensions\n",
    "num_channels = 1                                              # gray-channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Neural Networks learns faster with normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize to be in  the [0, 1] range:\n",
    "trainX = trainX.astype('float32') / 255.\n",
    "valX = valX.astype('float32') / 255.\n",
    "testAllX = testAllX.astype('float32') / 255.\n",
    "\n",
    "# reshape data to keras inputs --> (n_samples, img_rows, img_cols, n_channels):\n",
    "trainX = trainX.reshape(trainX.shape[0], img_height, img_width, num_channels)\n",
    "valX = valX.reshape(valX.shape[0], img_height, img_width, num_channels)\n",
    "testAllX = testAllX.reshape(testAllX.shape[0], img_height, img_width, num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import architecture of VAE model and its hyperparameters:\n",
    "from J16_AE_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Total AE Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 128, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 32)          4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "latent (Dense)               (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               8704      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 8, 8, 32)          4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 128, 128, 32)      4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "decoder_output (Conv2DTransp (None, 128, 128, 1)       129       \n",
      "=================================================================\n",
      "Total params: 57,681\n",
      "Trainable params: 56,017\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "batch_size  = 256\n",
    "epochs      = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checkpoint callback options: save model at 1'st epoch (inital model)\n",
    "\n",
    "https://stackoverflow.com/questions/54323960/save-keras-model-at-specific-epochs\n",
    "\"\"\"\n",
    "\n",
    "class CustomSaver(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch == 1:\n",
    "            self.model.save_weights(f\"{SAVE_FOLDER}/cp-0001.h5\")\n",
    "            \n",
    "# create and use callback:\n",
    "initial_checkpoint = CustomSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Checkpoint callback options: save model at every k'te epochs\n",
    "\"\"\"\n",
    "# Include the epoch in the file name (uses `str.format`):\n",
    "checkpoint_path = \"saved_models/latent16/cp-{epoch:04d}.h5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every k'te epochs:\n",
    "checkpoint = ModelCheckpoint(filepath = checkpoint_path,\n",
    "                             monitor='loss',           # name of the metrics to monitor\n",
    "                             verbose=1, \n",
    "                             #save_best_only=False,     # if False, the best model will not be overridden.\n",
    "                             save_weights_only=True,   # if True, only the weights of the models will be saved.\n",
    "                                                        # if False, the whole models will be saved.\n",
    "                             #mode='auto', \n",
    "                             period=200                  # save after every k'te epochs\n",
    "                            )\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "ae.save_weights(checkpoint_path.format(epoch=0))          # save for zero epoch (inital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checkpoint callback options: Early stopping\n",
    "https://www.tensorflow.org/guide/keras/custom_callback\n",
    "\"\"\"\n",
    "\n",
    "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
    "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
    "\n",
    "  Arguments:\n",
    "      patience: Number of epochs to wait after min has been hit. After this\n",
    "      number of no improvement, training stops.\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, patience=50):\n",
    "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        # best_weights to store the weights at which the minimum loss occurs.\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(\"loss\")\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (less).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create and Compile Model\"\"\"\n",
    "# import architecture of VAE model and its hyperparameters. learning rate choosen from graph above.\n",
    "ae = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.1842 - val_loss: 0.1420\n",
      "Epoch 2/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.1302 - val_loss: 0.1381\n",
      "Epoch 3/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.1048 - val_loss: 0.1334\n",
      "Epoch 4/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0849 - val_loss: 0.1284\n",
      "Epoch 5/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0693 - val_loss: 0.1231\n",
      "Epoch 6/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0531 - val_loss: 0.1175\n",
      "Epoch 7/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0377 - val_loss: 0.1116\n",
      "Epoch 8/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0276 - val_loss: 0.1059\n",
      "Epoch 9/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0203 - val_loss: 0.1009\n",
      "Epoch 10/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0158 - val_loss: 0.0968\n",
      "Epoch 11/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0129 - val_loss: 0.0938\n",
      "Epoch 12/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0110 - val_loss: 0.0915\n",
      "Epoch 13/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0095 - val_loss: 0.0900\n",
      "Epoch 14/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0085 - val_loss: 0.0892\n",
      "Epoch 15/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0077 - val_loss: 0.0891\n",
      "Epoch 16/1000\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.0070 - val_loss: 0.0896\n",
      "Epoch 17/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0065 - val_loss: 0.0908\n",
      "Epoch 18/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0061 - val_loss: 0.0924\n",
      "Epoch 19/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0056 - val_loss: 0.0946\n",
      "Epoch 20/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0053 - val_loss: 0.0971\n",
      "Epoch 21/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0051 - val_loss: 0.0998\n",
      "Epoch 22/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0048 - val_loss: 0.1026\n",
      "Epoch 23/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0046 - val_loss: 0.1056\n",
      "Epoch 24/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0043 - val_loss: 0.1083\n",
      "Epoch 25/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0043 - val_loss: 0.1111\n",
      "Epoch 26/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0040 - val_loss: 0.1137\n",
      "Epoch 27/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0039 - val_loss: 0.1160\n",
      "Epoch 28/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0037 - val_loss: 0.1179\n",
      "Epoch 29/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.1200\n",
      "Epoch 30/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0036 - val_loss: 0.1208\n",
      "Epoch 31/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0035 - val_loss: 0.1220\n",
      "Epoch 32/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0034 - val_loss: 0.1232\n",
      "Epoch 33/1000\n",
      "7/7 [==============================] - 1s 73ms/step - loss: 0.0033 - val_loss: 0.1215\n",
      "Epoch 34/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0032 - val_loss: 0.1220\n",
      "Epoch 35/1000\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.0032 - val_loss: 0.1215\n",
      "Epoch 36/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0029 - val_loss: 0.1202\n",
      "Epoch 37/1000\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.0029 - val_loss: 0.1165\n",
      "Epoch 38/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0030 - val_loss: 0.1164\n",
      "Epoch 39/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.1126\n",
      "Epoch 40/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0028 - val_loss: 0.1106\n",
      "Epoch 41/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0029 - val_loss: 0.1086\n",
      "Epoch 42/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0028 - val_loss: 0.0983\n",
      "Epoch 43/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0026 - val_loss: 0.0969\n",
      "Epoch 44/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0026 - val_loss: 0.0913\n",
      "Epoch 45/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0025 - val_loss: 0.0873\n",
      "Epoch 46/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0026 - val_loss: 0.0812\n",
      "Epoch 47/1000\n",
      "7/7 [==============================] - 1s 74ms/step - loss: 0.0024 - val_loss: 0.0757\n",
      "Epoch 48/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0024 - val_loss: 0.0713\n",
      "Epoch 49/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0023 - val_loss: 0.0649\n",
      "Epoch 50/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0023 - val_loss: 0.0561\n",
      "Epoch 51/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0024 - val_loss: 0.0562\n",
      "Epoch 52/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0493\n",
      "Epoch 53/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0022 - val_loss: 0.0465\n",
      "Epoch 54/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0022 - val_loss: 0.0406\n",
      "Epoch 55/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0022 - val_loss: 0.0409\n",
      "Epoch 56/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0021 - val_loss: 0.0334\n",
      "Epoch 57/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0022 - val_loss: 0.0307\n",
      "Epoch 58/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0020 - val_loss: 0.0283\n",
      "Epoch 59/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0021 - val_loss: 0.0263\n",
      "Epoch 60/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0020 - val_loss: 0.0219\n",
      "Epoch 61/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0020 - val_loss: 0.0201\n",
      "Epoch 62/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0020 - val_loss: 0.0169\n",
      "Epoch 63/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0020 - val_loss: 0.0139\n",
      "Epoch 64/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0019 - val_loss: 0.0119\n",
      "Epoch 65/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0021 - val_loss: 0.0115\n",
      "Epoch 66/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0019 - val_loss: 0.0098\n",
      "Epoch 67/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0018 - val_loss: 0.0097\n",
      "Epoch 68/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0018 - val_loss: 0.0080\n",
      "Epoch 69/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0018 - val_loss: 0.0078\n",
      "Epoch 70/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 0.0070\n",
      "Epoch 71/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0017 - val_loss: 0.0063\n",
      "Epoch 72/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 0.0058\n",
      "Epoch 73/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0017 - val_loss: 0.0055\n",
      "Epoch 74/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0018 - val_loss: 0.0047\n",
      "Epoch 75/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 76/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0017 - val_loss: 0.0037\n",
      "Epoch 77/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0016 - val_loss: 0.0042\n",
      "Epoch 78/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 79/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 80/1000\n",
      "7/7 [==============================] - 1s 71ms/step - loss: 0.0016 - val_loss: 0.0031\n",
      "Epoch 81/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 82/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 83/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 84/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 85/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 86/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 87/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 88/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 89/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 90/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 91/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 92/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 93/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 94/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 95/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 96/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 97/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 98/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 99/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 100/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 101/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 102/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 103/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 104/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 105/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 106/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 107/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 108/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 109/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 110/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 111/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 112/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 113/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 114/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 115/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 116/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 117/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 118/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 119/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 120/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 121/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 122/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 123/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 124/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 125/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 126/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 127/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 128/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 129/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 130/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 131/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 132/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 133/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 134/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 135/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 136/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 137/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 138/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 139/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 140/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 141/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 142/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 143/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 144/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 145/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 146/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 147/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 148/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 149/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 150/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 151/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 152/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 153/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 154/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 155/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 156/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 157/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 158/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 159/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 160/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 161/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 162/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 163/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 9.9221e-04 - val_loss: 0.0015\n",
      "Epoch 164/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 9.7944e-04 - val_loss: 0.0016\n",
      "Epoch 165/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.8888e-04 - val_loss: 0.0015\n",
      "Epoch 166/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.9662e-04 - val_loss: 0.0015\n",
      "Epoch 167/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 168/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 169/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 9.7815e-04 - val_loss: 0.0014\n",
      "Epoch 170/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 9.7542e-04 - val_loss: 0.0016\n",
      "Epoch 171/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.8467e-04 - val_loss: 0.0014\n",
      "Epoch 172/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 9.5824e-04 - val_loss: 0.0014\n",
      "Epoch 173/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 174/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 175/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.6065e-04 - val_loss: 0.0012\n",
      "Epoch 176/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 9.7501e-04 - val_loss: 0.0012\n",
      "Epoch 177/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 9.1473e-04 - val_loss: 0.0013\n",
      "Epoch 178/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 179/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 9.1377e-04 - val_loss: 0.0013\n",
      "Epoch 180/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.2403e-04 - val_loss: 0.0013\n",
      "Epoch 181/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.5776e-04 - val_loss: 0.0014\n",
      "Epoch 182/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 9.7704e-04 - val_loss: 0.0014\n",
      "Epoch 183/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 9.0024e-04 - val_loss: 0.0012\n",
      "Epoch 184/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.6838e-04 - val_loss: 0.0013\n",
      "Epoch 185/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 186/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.5500e-04 - val_loss: 0.0013\n",
      "Epoch 187/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.7279e-04 - val_loss: 0.0013\n",
      "Epoch 188/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 189/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 9.9343e-04 - val_loss: 0.0014\n",
      "Epoch 190/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 9.8512e-04 - val_loss: 0.0013\n",
      "Epoch 191/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.3327e-04 - val_loss: 0.0012\n",
      "Epoch 192/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.5563e-04 - val_loss: 0.0012\n",
      "Epoch 193/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 8.8692e-04 - val_loss: 0.0013\n",
      "Epoch 194/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.3672e-04 - val_loss: 0.0012\n",
      "Epoch 195/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 9.1404e-04 - val_loss: 0.0012\n",
      "Epoch 196/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 8.6614e-04 - val_loss: 0.0012\n",
      "Epoch 197/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.8200e-04 - val_loss: 0.0013\n",
      "Epoch 198/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.3631e-04 - val_loss: 0.0012\n",
      "Epoch 199/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.0748e-04 - val_loss: 0.0013\n",
      "Epoch 200/1000\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 8.3428e-04\n",
      "Epoch 00200: saving model to saved_models/latent16/cp-0200.h5\n",
      "7/7 [==============================] - 1s 98ms/step - loss: 8.3890e-04 - val_loss: 0.0012\n",
      "Epoch 201/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.4500e-04 - val_loss: 0.0014\n",
      "Epoch 202/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.8275e-04 - val_loss: 0.0012\n",
      "Epoch 203/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 8.6073e-04 - val_loss: 0.0012\n",
      "Epoch 204/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.3461e-04 - val_loss: 0.0013\n",
      "Epoch 205/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.5409e-04 - val_loss: 0.0012\n",
      "Epoch 206/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.7643e-04 - val_loss: 0.0012\n",
      "Epoch 207/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.3997e-04 - val_loss: 0.0013\n",
      "Epoch 208/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.2854e-04 - val_loss: 0.0012\n",
      "Epoch 209/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.1524e-04 - val_loss: 0.0012\n",
      "Epoch 210/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.4039e-04 - val_loss: 0.0011\n",
      "Epoch 211/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.3148e-04 - val_loss: 0.0011\n",
      "Epoch 212/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.8192e-04 - val_loss: 0.0012\n",
      "Epoch 213/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.4360e-04 - val_loss: 0.0012\n",
      "Epoch 214/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.3131e-04 - val_loss: 0.0013\n",
      "Epoch 215/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.6180e-04 - val_loss: 0.0013\n",
      "Epoch 216/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.2515e-04 - val_loss: 0.0011\n",
      "Epoch 217/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.6575e-04 - val_loss: 0.0013\n",
      "Epoch 218/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 8.1414e-04 - val_loss: 0.0011\n",
      "Epoch 219/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.7788e-04 - val_loss: 0.0012\n",
      "Epoch 220/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.3409e-04 - val_loss: 0.0011\n",
      "Epoch 221/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 8.0661e-04 - val_loss: 0.0011\n",
      "Epoch 222/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.2098e-04 - val_loss: 0.0013\n",
      "Epoch 223/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.5736e-04 - val_loss: 0.0012\n",
      "Epoch 224/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.1017e-04 - val_loss: 0.0012\n",
      "Epoch 225/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.5566e-04 - val_loss: 0.0013\n",
      "Epoch 226/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 8.5768e-04 - val_loss: 0.0011\n",
      "Epoch 227/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.2755e-04 - val_loss: 0.0010\n",
      "Epoch 228/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.4422e-04 - val_loss: 0.0011\n",
      "Epoch 229/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.2043e-04 - val_loss: 0.0012\n",
      "Epoch 230/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.6998e-04 - val_loss: 0.0011\n",
      "Epoch 231/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.4561e-04 - val_loss: 0.0012\n",
      "Epoch 232/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 7.8421e-04 - val_loss: 0.0011\n",
      "Epoch 233/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.2417e-04 - val_loss: 0.0012\n",
      "Epoch 234/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.2221e-04 - val_loss: 0.0013\n",
      "Epoch 235/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.3241e-04 - val_loss: 0.0013\n",
      "Epoch 236/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.4468e-04 - val_loss: 0.0013\n",
      "Epoch 237/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.0079e-04 - val_loss: 0.0013\n",
      "Epoch 238/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.4209e-04 - val_loss: 0.0013\n",
      "Epoch 239/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.8893e-04 - val_loss: 0.0012\n",
      "Epoch 240/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.2150e-04 - val_loss: 0.0014\n",
      "Epoch 241/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.0785e-04 - val_loss: 0.0011\n",
      "Epoch 242/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.4088e-04 - val_loss: 0.0012\n",
      "Epoch 243/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 7.7360e-04 - val_loss: 0.0011\n",
      "Epoch 244/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.1904e-04 - val_loss: 0.0011\n",
      "Epoch 245/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.0841e-04 - val_loss: 0.0012\n",
      "Epoch 246/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.9677e-04 - val_loss: 0.0015\n",
      "Epoch 247/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 8.4295e-04 - val_loss: 0.0011\n",
      "Epoch 248/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.5617e-04 - val_loss: 0.0011\n",
      "Epoch 249/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.0249e-04 - val_loss: 0.0012\n",
      "Epoch 250/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.2543e-04 - val_loss: 0.0011\n",
      "Epoch 251/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.4307e-04 - val_loss: 0.0013\n",
      "Epoch 252/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 9.0978e-04 - val_loss: 0.0011\n",
      "Epoch 253/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.5633e-04 - val_loss: 9.9609e-04\n",
      "Epoch 254/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.0651e-04 - val_loss: 0.0011\n",
      "Epoch 255/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 7.3715e-04 - val_loss: 0.0012\n",
      "Epoch 256/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.1604e-04 - val_loss: 0.0011\n",
      "Epoch 257/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.5901e-04 - val_loss: 0.0012\n",
      "Epoch 258/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.9738e-04 - val_loss: 0.0012\n",
      "Epoch 259/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.2043e-04 - val_loss: 0.0011\n",
      "Epoch 260/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.6322e-04 - val_loss: 0.0013\n",
      "Epoch 261/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.1726e-04 - val_loss: 0.0014\n",
      "Epoch 262/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.5250e-04 - val_loss: 0.0010\n",
      "Epoch 263/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.6543e-04 - val_loss: 0.0014\n",
      "Epoch 264/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.9774e-04 - val_loss: 0.0011\n",
      "Epoch 265/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.7652e-04 - val_loss: 0.0010\n",
      "Epoch 266/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.6514e-04 - val_loss: 0.0014\n",
      "Epoch 267/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.1477e-04 - val_loss: 0.0011\n",
      "Epoch 268/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.2511e-04 - val_loss: 0.0011\n",
      "Epoch 269/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.3274e-04 - val_loss: 0.0012\n",
      "Epoch 270/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 7.8877e-04 - val_loss: 0.0012\n",
      "Epoch 271/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 8.1455e-04 - val_loss: 0.0014\n",
      "Epoch 272/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.0300e-04 - val_loss: 0.0013\n",
      "Epoch 273/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.7260e-04 - val_loss: 0.0014\n",
      "Epoch 274/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.4894e-04 - val_loss: 0.0014\n",
      "Epoch 275/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.6936e-04 - val_loss: 0.0013\n",
      "Epoch 276/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.4414e-04 - val_loss: 0.0011\n",
      "Epoch 277/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.4462e-04 - val_loss: 0.0015\n",
      "Epoch 278/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.4599e-04 - val_loss: 0.0012\n",
      "Epoch 279/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 7.1547e-04 - val_loss: 0.0011\n",
      "Epoch 280/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.4015e-04 - val_loss: 0.0013\n",
      "Epoch 281/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.3916e-04 - val_loss: 0.0012\n",
      "Epoch 282/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.7443e-04 - val_loss: 0.0013\n",
      "Epoch 283/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 9.0298e-04 - val_loss: 0.0013\n",
      "Epoch 284/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.0233e-04 - val_loss: 0.0016\n",
      "Epoch 285/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.7740e-04 - val_loss: 0.0017\n",
      "Epoch 286/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 8.3166e-04 - val_loss: 0.0014\n",
      "Epoch 287/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.4724e-04 - val_loss: 0.0014\n",
      "Epoch 288/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5879e-04 - val_loss: 0.0015\n",
      "Epoch 289/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.2980e-04 - val_loss: 0.0013\n",
      "Epoch 290/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.7800e-04 - val_loss: 0.0014\n",
      "Epoch 291/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5474e-04 - val_loss: 0.0013\n",
      "Epoch 292/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5056e-04 - val_loss: 0.0013\n",
      "Epoch 293/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.3372e-04 - val_loss: 0.0013\n",
      "Epoch 294/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.2086e-04 - val_loss: 0.0013\n",
      "Epoch 295/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.4270e-04 - val_loss: 0.0011\n",
      "Epoch 296/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.8692e-04 - val_loss: 0.0013\n",
      "Epoch 297/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.4749e-04 - val_loss: 0.0011\n",
      "Epoch 298/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.4699e-04 - val_loss: 0.0012\n",
      "Epoch 299/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.6116e-04 - val_loss: 0.0011\n",
      "Epoch 300/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.3283e-04 - val_loss: 0.0012\n",
      "Epoch 301/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.1906e-04 - val_loss: 0.0010\n",
      "Epoch 302/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.7241e-04 - val_loss: 0.0010\n",
      "Epoch 303/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.9479e-04 - val_loss: 0.0011\n",
      "Epoch 304/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5887e-04 - val_loss: 0.0013\n",
      "Epoch 305/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.3937e-04 - val_loss: 0.0010\n",
      "Epoch 306/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.4170e-04 - val_loss: 9.8540e-04\n",
      "Epoch 307/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 6.9556e-04 - val_loss: 0.0012\n",
      "Epoch 308/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.7389e-04 - val_loss: 9.1053e-04\n",
      "Epoch 309/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 6.5751e-04 - val_loss: 9.3251e-04\n",
      "Epoch 310/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8879e-04 - val_loss: 0.0012\n",
      "Epoch 311/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.4480e-04 - val_loss: 9.4758e-04\n",
      "Epoch 312/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.1115e-04 - val_loss: 8.6304e-04\n",
      "Epoch 313/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.7253e-04 - val_loss: 9.9001e-04\n",
      "Epoch 314/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.1379e-04 - val_loss: 9.8596e-04\n",
      "Epoch 315/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5951e-04 - val_loss: 0.0012\n",
      "Epoch 316/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.0404e-04 - val_loss: 9.1938e-04\n",
      "Epoch 317/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.0083e-04 - val_loss: 0.0011\n",
      "Epoch 318/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.0010e-04 - val_loss: 9.1201e-04\n",
      "Epoch 319/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.2548e-04 - val_loss: 0.0010\n",
      "Epoch 320/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.9891e-04 - val_loss: 9.0914e-04\n",
      "Epoch 321/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.0799e-04 - val_loss: 9.4028e-04\n",
      "Epoch 322/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8471e-04 - val_loss: 9.2164e-04\n",
      "Epoch 323/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.7619e-04 - val_loss: 0.0012\n",
      "Epoch 324/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5141e-04 - val_loss: 9.5163e-04\n",
      "Epoch 325/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.8128e-04 - val_loss: 9.9237e-04\n",
      "Epoch 326/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8936e-04 - val_loss: 9.4346e-04\n",
      "Epoch 327/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.3391e-04 - val_loss: 0.0012\n",
      "Epoch 328/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.0245e-04 - val_loss: 0.0011\n",
      "Epoch 329/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.9652e-04 - val_loss: 0.0010\n",
      "Epoch 330/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.2011e-04 - val_loss: 0.0012\n",
      "Epoch 331/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.7235e-04 - val_loss: 0.0010\n",
      "Epoch 332/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8974e-04 - val_loss: 9.2245e-04\n",
      "Epoch 333/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.7298e-04 - val_loss: 0.0011\n",
      "Epoch 334/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.1059e-04 - val_loss: 9.6641e-04\n",
      "Epoch 335/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.6352e-04 - val_loss: 0.0010\n",
      "Epoch 336/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5400e-04 - val_loss: 9.0008e-04\n",
      "Epoch 337/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.2374e-04 - val_loss: 0.0012\n",
      "Epoch 338/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.4414e-04 - val_loss: 0.0010\n",
      "Epoch 339/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.7031e-04 - val_loss: 0.0010\n",
      "Epoch 340/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.2172e-04 - val_loss: 0.0010\n",
      "Epoch 341/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.9164e-04 - val_loss: 0.0010\n",
      "Epoch 342/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.0532e-04 - val_loss: 0.0012\n",
      "Epoch 343/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.0537e-04 - val_loss: 0.0013\n",
      "Epoch 344/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5977e-04 - val_loss: 0.0011\n",
      "Epoch 345/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.8850e-04 - val_loss: 0.0013\n",
      "Epoch 346/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 6.5440e-04 - val_loss: 9.7197e-04\n",
      "Epoch 347/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6533e-04 - val_loss: 0.0011\n",
      "Epoch 348/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.9656e-04 - val_loss: 0.0011\n",
      "Epoch 349/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 6.5186e-04 - val_loss: 0.0010\n",
      "Epoch 350/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 6.2089e-04 - val_loss: 0.0010\n",
      "Epoch 351/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.3749e-04 - val_loss: 9.4422e-04\n",
      "Epoch 352/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.4208e-04 - val_loss: 8.4490e-04\n",
      "Epoch 353/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.5761e-04 - val_loss: 9.3842e-04\n",
      "Epoch 354/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8601e-04 - val_loss: 0.0010\n",
      "Epoch 355/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6966e-04 - val_loss: 0.0010\n",
      "Epoch 356/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.1830e-04 - val_loss: 0.0012\n",
      "Epoch 357/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 8.1672e-04 - val_loss: 0.0012\n",
      "Epoch 358/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.6071e-04 - val_loss: 0.0011\n",
      "Epoch 359/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.1961e-04 - val_loss: 0.0010\n",
      "Epoch 360/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.8933e-04 - val_loss: 9.3870e-04\n",
      "Epoch 361/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8404e-04 - val_loss: 9.8265e-04\n",
      "Epoch 362/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8937e-04 - val_loss: 8.9694e-04\n",
      "Epoch 363/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8986e-04 - val_loss: 9.6301e-04\n",
      "Epoch 364/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.1479e-04 - val_loss: 8.7639e-04\n",
      "Epoch 365/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.1944e-04 - val_loss: 9.1842e-04\n",
      "Epoch 366/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.6143e-04 - val_loss: 9.5043e-04\n",
      "Epoch 367/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.5206e-04 - val_loss: 9.5256e-04\n",
      "Epoch 368/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6830e-04 - val_loss: 8.8687e-04\n",
      "Epoch 369/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.4460e-04 - val_loss: 8.6891e-04\n",
      "Epoch 370/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.3881e-04 - val_loss: 9.6830e-04\n",
      "Epoch 371/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 6.1817e-04 - val_loss: 0.0011\n",
      "Epoch 372/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2597e-04 - val_loss: 8.3996e-04\n",
      "Epoch 373/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.2594e-04 - val_loss: 0.0012\n",
      "Epoch 374/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.6169e-04 - val_loss: 8.1416e-04\n",
      "Epoch 375/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.7805e-04 - val_loss: 0.0012\n",
      "Epoch 376/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.0519e-04 - val_loss: 7.5558e-04\n",
      "Epoch 377/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.0687e-04 - val_loss: 9.6687e-04\n",
      "Epoch 378/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.9510e-04 - val_loss: 0.0012\n",
      "Epoch 379/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.4365e-04 - val_loss: 0.0011\n",
      "Epoch 380/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.9587e-04 - val_loss: 0.0012\n",
      "Epoch 381/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1593e-04 - val_loss: 0.0011\n",
      "Epoch 382/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6471e-04 - val_loss: 0.0010\n",
      "Epoch 383/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.5722e-04 - val_loss: 0.0013\n",
      "Epoch 384/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.7611e-04 - val_loss: 9.8924e-04\n",
      "Epoch 385/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6614e-04 - val_loss: 0.0011\n",
      "Epoch 386/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.4734e-04 - val_loss: 0.0013\n",
      "Epoch 387/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2520e-04 - val_loss: 0.0012\n",
      "Epoch 388/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.3221e-04 - val_loss: 0.0012\n",
      "Epoch 389/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.3255e-04 - val_loss: 0.0012\n",
      "Epoch 390/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2526e-04 - val_loss: 0.0011\n",
      "Epoch 391/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.3197e-04 - val_loss: 0.0011\n",
      "Epoch 392/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2350e-04 - val_loss: 9.9155e-04\n",
      "Epoch 393/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.3141e-04 - val_loss: 0.0010\n",
      "Epoch 394/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.9369e-04 - val_loss: 0.0010\n",
      "Epoch 395/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0632e-04 - val_loss: 9.7528e-04\n",
      "Epoch 396/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.3493e-04 - val_loss: 0.0010\n",
      "Epoch 397/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.9483e-04 - val_loss: 0.0011\n",
      "Epoch 398/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.0993e-04 - val_loss: 0.0010\n",
      "Epoch 399/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.4310e-04 - val_loss: 0.0018\n",
      "Epoch 400/1000\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 6.7747e-04\n",
      "Epoch 00400: saving model to saved_models/latent16/cp-0400.h5\n",
      "7/7 [==============================] - 1s 100ms/step - loss: 6.9865e-04 - val_loss: 0.0011\n",
      "Epoch 401/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.7814e-04 - val_loss: 0.0014\n",
      "Epoch 402/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.9145e-04 - val_loss: 0.0014\n",
      "Epoch 403/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.7599e-04 - val_loss: 0.0012\n",
      "Epoch 404/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.8968e-04 - val_loss: 0.0011\n",
      "Epoch 405/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.1567e-04 - val_loss: 0.0010\n",
      "Epoch 406/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.5838e-04 - val_loss: 9.5618e-04\n",
      "Epoch 407/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.9869e-04 - val_loss: 9.9766e-04\n",
      "Epoch 408/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.8498e-04 - val_loss: 0.0011\n",
      "Epoch 409/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 7.1489e-04 - val_loss: 0.0011\n",
      "Epoch 410/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.9036e-04 - val_loss: 0.0024\n",
      "Epoch 411/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.1590e-04 - val_loss: 0.0012\n",
      "Epoch 412/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2313e-04 - val_loss: 0.0010\n",
      "Epoch 413/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6003e-04 - val_loss: 9.5459e-04\n",
      "Epoch 414/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0071e-04 - val_loss: 9.0863e-04\n",
      "Epoch 415/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2776e-04 - val_loss: 0.0011\n",
      "Epoch 416/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.3072e-04 - val_loss: 0.0010\n",
      "Epoch 417/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.8797e-04 - val_loss: 8.3317e-04\n",
      "Epoch 418/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.0493e-04 - val_loss: 8.8175e-04\n",
      "Epoch 419/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.8082e-04 - val_loss: 0.0010\n",
      "Epoch 420/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0601e-04 - val_loss: 8.3541e-04\n",
      "Epoch 421/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8307e-04 - val_loss: 0.0010\n",
      "Epoch 422/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9639e-04 - val_loss: 0.0010\n",
      "Epoch 423/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.3304e-04 - val_loss: 0.0012\n",
      "Epoch 424/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2172e-04 - val_loss: 0.0011\n",
      "Epoch 425/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6133e-04 - val_loss: 0.0011\n",
      "Epoch 426/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.5353e-04 - val_loss: 0.0012\n",
      "Epoch 427/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.2682e-04 - val_loss: 0.0011\n",
      "Epoch 428/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1056e-04 - val_loss: 0.0010\n",
      "Epoch 429/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1024e-04 - val_loss: 9.4212e-04\n",
      "Epoch 430/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.3760e-04 - val_loss: 0.0011\n",
      "Epoch 431/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.5182e-04 - val_loss: 8.3796e-04\n",
      "Epoch 432/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8912e-04 - val_loss: 0.0011\n",
      "Epoch 433/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.8472e-04 - val_loss: 9.0148e-04\n",
      "Epoch 434/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.5405e-04 - val_loss: 7.9522e-04\n",
      "Epoch 435/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0146e-04 - val_loss: 7.7799e-04\n",
      "Epoch 436/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.4179e-04 - val_loss: 0.0010\n",
      "Epoch 437/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6877e-04 - val_loss: 9.2226e-04\n",
      "Epoch 438/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.9976e-04 - val_loss: 8.4250e-04\n",
      "Epoch 439/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.8507e-04 - val_loss: 8.1782e-04\n",
      "Epoch 440/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.3146e-04 - val_loss: 8.8672e-04\n",
      "Epoch 441/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1996e-04 - val_loss: 9.3238e-04\n",
      "Epoch 442/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.4135e-04 - val_loss: 9.8778e-04\n",
      "Epoch 443/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.1505e-04 - val_loss: 0.0010\n",
      "Epoch 444/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8917e-04 - val_loss: 8.5735e-04\n",
      "Epoch 445/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0207e-04 - val_loss: 8.6275e-04\n",
      "Epoch 446/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2507e-04 - val_loss: 7.2213e-04\n",
      "Epoch 447/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6805e-04 - val_loss: 8.7716e-04\n",
      "Epoch 448/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7305e-04 - val_loss: 8.9919e-04\n",
      "Epoch 449/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6512e-04 - val_loss: 7.7512e-04\n",
      "Epoch 450/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1488e-04 - val_loss: 9.3418e-04\n",
      "Epoch 451/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1430e-04 - val_loss: 9.3016e-04\n",
      "Epoch 452/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.3041e-04 - val_loss: 9.0873e-04\n",
      "Epoch 453/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1464e-04 - val_loss: 9.1209e-04\n",
      "Epoch 454/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.9353e-04 - val_loss: 8.4867e-04\n",
      "Epoch 455/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7137e-04 - val_loss: 8.9501e-04\n",
      "Epoch 456/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.4638e-04 - val_loss: 7.6691e-04\n",
      "Epoch 457/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9326e-04 - val_loss: 8.9857e-04\n",
      "Epoch 458/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.2416e-04 - val_loss: 8.4053e-04\n",
      "Epoch 459/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7107e-04 - val_loss: 8.3298e-04\n",
      "Epoch 460/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9746e-04 - val_loss: 7.9642e-04\n",
      "Epoch 461/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9257e-04 - val_loss: 7.9615e-04\n",
      "Epoch 462/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.5808e-04 - val_loss: 8.4002e-04\n",
      "Epoch 463/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.0760e-04 - val_loss: 7.8862e-04\n",
      "Epoch 464/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.5565e-04 - val_loss: 7.5342e-04\n",
      "Epoch 465/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8598e-04 - val_loss: 8.0267e-04\n",
      "Epoch 466/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9252e-04 - val_loss: 7.9206e-04\n",
      "Epoch 467/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.5490e-04 - val_loss: 7.7049e-04\n",
      "Epoch 468/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.0841e-04 - val_loss: 7.3687e-04\n",
      "Epoch 469/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.7765e-04 - val_loss: 9.5453e-04\n",
      "Epoch 470/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6280e-04 - val_loss: 0.0013\n",
      "Epoch 471/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.5133e-04 - val_loss: 9.5363e-04\n",
      "Epoch 472/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.4171e-04 - val_loss: 8.8786e-04\n",
      "Epoch 473/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9370e-04 - val_loss: 0.0010\n",
      "Epoch 474/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1540e-04 - val_loss: 0.0012\n",
      "Epoch 475/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7507e-04 - val_loss: 0.0011\n",
      "Epoch 476/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.3134e-04 - val_loss: 0.0012\n",
      "Epoch 477/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9560e-04 - val_loss: 0.0011\n",
      "Epoch 478/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.3001e-04 - val_loss: 9.8340e-04\n",
      "Epoch 479/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.1293e-04 - val_loss: 0.0010\n",
      "Epoch 480/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7597e-04 - val_loss: 8.4449e-04\n",
      "Epoch 481/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.4367e-04 - val_loss: 9.7006e-04\n",
      "Epoch 482/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8390e-04 - val_loss: 9.2698e-04\n",
      "Epoch 483/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.4298e-04 - val_loss: 9.2461e-04\n",
      "Epoch 484/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5801e-04 - val_loss: 8.3748e-04\n",
      "Epoch 485/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.7555e-04 - val_loss: 9.9100e-04\n",
      "Epoch 486/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4961e-04 - val_loss: 8.2985e-04\n",
      "Epoch 487/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.3160e-04 - val_loss: 8.5450e-04\n",
      "Epoch 488/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.2552e-04 - val_loss: 8.9326e-04\n",
      "Epoch 489/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.3484e-04 - val_loss: 7.3515e-04\n",
      "Epoch 490/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.7398e-04 - val_loss: 9.5692e-04\n",
      "Epoch 491/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6092e-04 - val_loss: 8.1047e-04\n",
      "Epoch 492/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7179e-04 - val_loss: 8.0483e-04\n",
      "Epoch 493/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8867e-04 - val_loss: 9.0754e-04\n",
      "Epoch 494/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5590e-04 - val_loss: 0.0010\n",
      "Epoch 495/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.2146e-04 - val_loss: 8.1331e-04\n",
      "Epoch 496/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.4188e-04 - val_loss: 7.8629e-04\n",
      "Epoch 497/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6203e-04 - val_loss: 7.7311e-04\n",
      "Epoch 498/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0290e-04 - val_loss: 7.7423e-04\n",
      "Epoch 499/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1647e-04 - val_loss: 9.1340e-04\n",
      "Epoch 500/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1749e-04 - val_loss: 9.1905e-04\n",
      "Epoch 501/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.2805e-04 - val_loss: 7.7949e-04\n",
      "Epoch 502/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8436e-04 - val_loss: 9.0852e-04\n",
      "Epoch 503/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6131e-04 - val_loss: 7.9691e-04\n",
      "Epoch 504/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7556e-04 - val_loss: 7.4155e-04\n",
      "Epoch 505/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8301e-04 - val_loss: 8.8151e-04\n",
      "Epoch 506/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6510e-04 - val_loss: 8.9383e-04\n",
      "Epoch 507/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4367e-04 - val_loss: 8.0482e-04\n",
      "Epoch 508/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.7272e-04 - val_loss: 7.4320e-04\n",
      "Epoch 509/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3617e-04 - val_loss: 9.7327e-04\n",
      "Epoch 510/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.6495e-04 - val_loss: 8.1053e-04\n",
      "Epoch 511/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 5.1576e-04 - val_loss: 7.7108e-04\n",
      "Epoch 512/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.1735e-04 - val_loss: 7.2845e-04\n",
      "Epoch 513/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5919e-04 - val_loss: 7.6482e-04\n",
      "Epoch 514/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4637e-04 - val_loss: 7.6877e-04\n",
      "Epoch 515/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.9327e-04 - val_loss: 7.2542e-04\n",
      "Epoch 516/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5263e-04 - val_loss: 8.1661e-04\n",
      "Epoch 517/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5880e-04 - val_loss: 7.6704e-04\n",
      "Epoch 518/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.6949e-04 - val_loss: 8.2051e-04\n",
      "Epoch 519/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5608e-04 - val_loss: 9.0411e-04\n",
      "Epoch 520/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.5932e-04 - val_loss: 0.0011\n",
      "Epoch 521/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.1158e-04 - val_loss: 0.0010\n",
      "Epoch 522/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9932e-04 - val_loss: 9.3229e-04\n",
      "Epoch 523/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0460e-04 - val_loss: 9.0135e-04\n",
      "Epoch 524/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.6467e-04 - val_loss: 8.6599e-04\n",
      "Epoch 525/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 7.2135e-04 - val_loss: 0.0011\n",
      "Epoch 526/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.9460e-04 - val_loss: 0.0011\n",
      "Epoch 527/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.8643e-04 - val_loss: 0.0011\n",
      "Epoch 528/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.3252e-04 - val_loss: 0.0010\n",
      "Epoch 529/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.8524e-04 - val_loss: 9.4814e-04\n",
      "Epoch 530/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9855e-04 - val_loss: 8.9777e-04\n",
      "Epoch 531/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 6.4138e-04 - val_loss: 0.0010\n",
      "Epoch 532/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.6650e-04 - val_loss: 0.0013\n",
      "Epoch 533/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.0043e-04 - val_loss: 0.0013\n",
      "Epoch 534/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6916e-04 - val_loss: 9.0656e-04\n",
      "Epoch 535/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.4230e-04 - val_loss: 7.9743e-04\n",
      "Epoch 536/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3144e-04 - val_loss: 7.3040e-04\n",
      "Epoch 537/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6033e-04 - val_loss: 8.6919e-04\n",
      "Epoch 538/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6524e-04 - val_loss: 7.6477e-04\n",
      "Epoch 539/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4190e-04 - val_loss: 9.7400e-04\n",
      "Epoch 540/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.4846e-04 - val_loss: 7.1478e-04\n",
      "Epoch 541/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.5975e-04 - val_loss: 8.8517e-04\n",
      "Epoch 542/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 7.3437e-04 - val_loss: 0.0027\n",
      "Epoch 543/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0711e-04 - val_loss: 0.0013\n",
      "Epoch 544/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7428e-04 - val_loss: 0.0012\n",
      "Epoch 545/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.6007e-04 - val_loss: 0.0012\n",
      "Epoch 546/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4041e-04 - val_loss: 0.0012\n",
      "Epoch 547/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6010e-04 - val_loss: 0.0012\n",
      "Epoch 548/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2658e-04 - val_loss: 0.0011\n",
      "Epoch 549/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.2370e-04 - val_loss: 9.9519e-04\n",
      "Epoch 550/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4141e-04 - val_loss: 9.2275e-04\n",
      "Epoch 551/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.6015e-04 - val_loss: 9.4496e-04\n",
      "Epoch 552/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2783e-04 - val_loss: 8.7291e-04\n",
      "Epoch 553/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.1575e-04 - val_loss: 8.0563e-04\n",
      "Epoch 554/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5605e-04 - val_loss: 7.8684e-04\n",
      "Epoch 555/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4465e-04 - val_loss: 8.5285e-04\n",
      "Epoch 556/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3608e-04 - val_loss: 7.2818e-04\n",
      "Epoch 557/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4657e-04 - val_loss: 8.5847e-04\n",
      "Epoch 558/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3734e-04 - val_loss: 8.0205e-04\n",
      "Epoch 559/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4439e-04 - val_loss: 8.2305e-04\n",
      "Epoch 560/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4649e-04 - val_loss: 7.7357e-04\n",
      "Epoch 561/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8549e-04 - val_loss: 8.4490e-04\n",
      "Epoch 562/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7122e-04 - val_loss: 9.2618e-04\n",
      "Epoch 563/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 6.0539e-04 - val_loss: 8.7989e-04\n",
      "Epoch 564/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6463e-04 - val_loss: 8.9038e-04\n",
      "Epoch 565/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9633e-04 - val_loss: 9.4759e-04\n",
      "Epoch 566/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.6020e-04 - val_loss: 0.0010\n",
      "Epoch 567/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.5841e-04 - val_loss: 0.0010\n",
      "Epoch 568/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8240e-04 - val_loss: 9.2904e-04\n",
      "Epoch 569/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4909e-04 - val_loss: 9.6922e-04\n",
      "Epoch 570/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8088e-04 - val_loss: 8.5088e-04\n",
      "Epoch 571/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3484e-04 - val_loss: 8.6415e-04\n",
      "Epoch 572/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6446e-04 - val_loss: 7.6461e-04\n",
      "Epoch 573/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.0868e-04 - val_loss: 9.3445e-04\n",
      "Epoch 574/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4131e-04 - val_loss: 8.0779e-04\n",
      "Epoch 575/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7255e-04 - val_loss: 7.7527e-04\n",
      "Epoch 576/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2480e-04 - val_loss: 7.5310e-04\n",
      "Epoch 577/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3507e-04 - val_loss: 7.7682e-04\n",
      "Epoch 578/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.7533e-04 - val_loss: 8.7167e-04\n",
      "Epoch 579/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.3046e-04 - val_loss: 8.0403e-04\n",
      "Epoch 580/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.5715e-04 - val_loss: 8.6972e-04\n",
      "Epoch 581/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2480e-04 - val_loss: 8.5028e-04\n",
      "Epoch 582/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4006e-04 - val_loss: 8.2879e-04\n",
      "Epoch 583/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1041e-04 - val_loss: 9.9712e-04\n",
      "Epoch 584/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3607e-04 - val_loss: 7.2139e-04\n",
      "Epoch 585/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8234e-04 - val_loss: 9.3647e-04\n",
      "Epoch 586/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0452e-04 - val_loss: 9.0994e-04\n",
      "Epoch 587/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1052e-04 - val_loss: 7.6688e-04\n",
      "Epoch 588/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8591e-04 - val_loss: 8.3962e-04\n",
      "Epoch 589/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.5904e-04 - val_loss: 7.0696e-04\n",
      "Epoch 590/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.6223e-04 - val_loss: 7.9432e-04\n",
      "Epoch 591/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1818e-04 - val_loss: 9.6401e-04\n",
      "Epoch 592/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4565e-04 - val_loss: 8.2198e-04\n",
      "Epoch 593/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.3808e-04 - val_loss: 0.0015\n",
      "Epoch 594/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6856e-04 - val_loss: 0.0012\n",
      "Epoch 595/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4573e-04 - val_loss: 0.0011\n",
      "Epoch 596/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3357e-04 - val_loss: 0.0011\n",
      "Epoch 597/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2860e-04 - val_loss: 8.0638e-04\n",
      "Epoch 598/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1011e-04 - val_loss: 7.0746e-04\n",
      "Epoch 599/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.0599e-04 - val_loss: 7.0328e-04\n",
      "Epoch 600/1000\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 5.4224e-04\n",
      "Epoch 00600: saving model to saved_models/latent16/cp-0600.h5\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 5.4145e-04 - val_loss: 7.0006e-04\n",
      "Epoch 601/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.9637e-04 - val_loss: 7.1547e-04\n",
      "Epoch 602/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1403e-04 - val_loss: 7.5065e-04\n",
      "Epoch 603/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3432e-04 - val_loss: 6.9710e-04\n",
      "Epoch 604/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4990e-04 - val_loss: 7.7094e-04\n",
      "Epoch 605/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3400e-04 - val_loss: 9.5163e-04\n",
      "Epoch 606/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.9052e-04 - val_loss: 7.5444e-04\n",
      "Epoch 607/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4701e-04 - val_loss: 8.3844e-04\n",
      "Epoch 608/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.7558e-04 - val_loss: 8.5507e-04\n",
      "Epoch 609/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.3688e-04 - val_loss: 7.8465e-04\n",
      "Epoch 610/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3904e-04 - val_loss: 7.4141e-04\n",
      "Epoch 611/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2073e-04 - val_loss: 7.0347e-04\n",
      "Epoch 612/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9933e-04 - val_loss: 7.3202e-04\n",
      "Epoch 613/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3520e-04 - val_loss: 7.0257e-04\n",
      "Epoch 614/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.1559e-04 - val_loss: 6.7294e-04\n",
      "Epoch 615/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.1304e-04 - val_loss: 6.8911e-04\n",
      "Epoch 616/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2600e-04 - val_loss: 6.9828e-04\n",
      "Epoch 617/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1396e-04 - val_loss: 7.4618e-04\n",
      "Epoch 618/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9809e-04 - val_loss: 7.8876e-04\n",
      "Epoch 619/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1470e-04 - val_loss: 7.5045e-04\n",
      "Epoch 620/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 4.8864e-04 - val_loss: 8.6203e-04\n",
      "Epoch 621/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.2456e-04 - val_loss: 7.2105e-04\n",
      "Epoch 622/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9179e-04 - val_loss: 6.6451e-04\n",
      "Epoch 623/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.8771e-04 - val_loss: 6.9723e-04\n",
      "Epoch 624/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.4482e-04 - val_loss: 8.6771e-04\n",
      "Epoch 625/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6456e-04 - val_loss: 7.0538e-04\n",
      "Epoch 626/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.1096e-04 - val_loss: 8.3915e-04\n",
      "Epoch 627/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 6.0538e-04 - val_loss: 8.6774e-04\n",
      "Epoch 628/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.5939e-04 - val_loss: 7.4960e-04\n",
      "Epoch 629/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3007e-04 - val_loss: 7.2144e-04\n",
      "Epoch 630/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3644e-04 - val_loss: 7.5838e-04\n",
      "Epoch 631/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4807e-04 - val_loss: 8.9034e-04\n",
      "Epoch 632/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1531e-04 - val_loss: 9.8656e-04\n",
      "Epoch 633/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9475e-04 - val_loss: 8.4404e-04\n",
      "Epoch 634/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9771e-04 - val_loss: 9.4418e-04\n",
      "Epoch 635/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1885e-04 - val_loss: 0.0010\n",
      "Epoch 636/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9724e-04 - val_loss: 8.5197e-04\n",
      "Epoch 637/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.0898e-04 - val_loss: 9.2140e-04\n",
      "Epoch 638/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8929e-04 - val_loss: 7.9964e-04\n",
      "Epoch 639/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2968e-04 - val_loss: 7.8051e-04\n",
      "Epoch 640/1000\n",
      "7/7 [==============================] - 1s 72ms/step - loss: 4.8234e-04 - val_loss: 7.6621e-04\n",
      "Epoch 641/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.3246e-04 - val_loss: 7.6634e-04\n",
      "Epoch 642/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0802e-04 - val_loss: 6.7866e-04\n",
      "Epoch 643/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0039e-04 - val_loss: 7.5817e-04\n",
      "Epoch 644/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1357e-04 - val_loss: 7.9730e-04\n",
      "Epoch 645/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4343e-04 - val_loss: 7.5854e-04\n",
      "Epoch 646/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.3538e-04 - val_loss: 7.6085e-04\n",
      "Epoch 647/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.9876e-04 - val_loss: 8.5227e-04\n",
      "Epoch 648/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9392e-04 - val_loss: 6.9358e-04\n",
      "Epoch 649/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0686e-04 - val_loss: 7.0547e-04\n",
      "Epoch 650/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.9984e-04 - val_loss: 6.9592e-04\n",
      "Epoch 651/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.8528e-04 - val_loss: 7.5675e-04\n",
      "Epoch 652/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8555e-04 - val_loss: 7.3539e-04\n",
      "Epoch 653/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.9946e-04 - val_loss: 8.8285e-04\n",
      "Epoch 654/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1690e-04 - val_loss: 7.6602e-04\n",
      "Epoch 655/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1510e-04 - val_loss: 6.4240e-04\n",
      "Epoch 656/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1624e-04 - val_loss: 7.7008e-04\n",
      "Epoch 657/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2522e-04 - val_loss: 7.9499e-04\n",
      "Epoch 658/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.9465e-04 - val_loss: 9.0296e-04\n",
      "Epoch 659/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0109e-04 - val_loss: 6.6394e-04\n",
      "Epoch 660/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6080e-04 - val_loss: 9.9262e-04\n",
      "Epoch 661/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2400e-04 - val_loss: 8.3443e-04\n",
      "Epoch 662/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4889e-04 - val_loss: 7.2736e-04\n",
      "Epoch 663/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.5905e-04 - val_loss: 8.0934e-04\n",
      "Epoch 664/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1569e-04 - val_loss: 7.4123e-04\n",
      "Epoch 665/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5040e-04 - val_loss: 7.9026e-04\n",
      "Epoch 666/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1296e-04 - val_loss: 9.3166e-04\n",
      "Epoch 667/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.5981e-04 - val_loss: 7.3149e-04\n",
      "Epoch 668/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.0005e-04 - val_loss: 8.4454e-04\n",
      "Epoch 669/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1663e-04 - val_loss: 7.2461e-04\n",
      "Epoch 670/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9709e-04 - val_loss: 7.5797e-04\n",
      "Epoch 671/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.7259e-04 - val_loss: 8.5241e-04\n",
      "Epoch 672/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1386e-04 - val_loss: 9.0057e-04\n",
      "Epoch 673/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4048e-04 - val_loss: 9.7227e-04\n",
      "Epoch 674/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6184e-04 - val_loss: 8.8849e-04\n",
      "Epoch 675/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3820e-04 - val_loss: 8.0378e-04\n",
      "Epoch 676/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2986e-04 - val_loss: 8.2405e-04\n",
      "Epoch 677/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.9536e-04 - val_loss: 9.5466e-04\n",
      "Epoch 678/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.5403e-04 - val_loss: 8.4677e-04\n",
      "Epoch 679/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3242e-04 - val_loss: 7.5346e-04\n",
      "Epoch 680/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.2555e-04 - val_loss: 9.8787e-04\n",
      "Epoch 681/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.9536e-04 - val_loss: 9.3822e-04\n",
      "Epoch 682/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1567e-04 - val_loss: 8.3293e-04\n",
      "Epoch 683/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.7278e-04 - val_loss: 8.4934e-04\n",
      "Epoch 684/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9502e-04 - val_loss: 7.6969e-04\n",
      "Epoch 685/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4959e-04 - val_loss: 7.2858e-04\n",
      "Epoch 686/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.6436e-04 - val_loss: 7.5972e-04\n",
      "Epoch 687/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8379e-04 - val_loss: 8.1798e-04\n",
      "Epoch 688/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3416e-04 - val_loss: 7.5085e-04\n",
      "Epoch 689/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3824e-04 - val_loss: 7.9666e-04\n",
      "Epoch 690/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4106e-04 - val_loss: 8.0008e-04\n",
      "Epoch 691/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4294e-04 - val_loss: 0.0019\n",
      "Epoch 692/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3919e-04 - val_loss: 0.0030\n",
      "Epoch 693/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2783e-04 - val_loss: 0.0036\n",
      "Epoch 694/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.5952e-04 - val_loss: 0.0033\n",
      "Epoch 695/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0818e-04 - val_loss: 0.0028\n",
      "Epoch 696/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6938e-04 - val_loss: 0.0025\n",
      "Epoch 697/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.6744e-04 - val_loss: 0.0023\n",
      "Epoch 698/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8773e-04 - val_loss: 0.0022\n",
      "Epoch 699/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8366e-04 - val_loss: 0.0017\n",
      "Epoch 700/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8323e-04 - val_loss: 0.0017\n",
      "Epoch 701/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2752e-04 - val_loss: 0.0013\n",
      "Epoch 702/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0905e-04 - val_loss: 0.0014\n",
      "Epoch 703/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8844e-04 - val_loss: 0.0012\n",
      "Epoch 704/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.0148e-04 - val_loss: 0.0010\n",
      "Epoch 705/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.8350e-04 - val_loss: 9.5661e-04\n",
      "Epoch 706/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.8244e-04 - val_loss: 9.3188e-04\n",
      "Epoch 707/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.9380e-04 - val_loss: 0.0010\n",
      "Epoch 708/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0285e-04 - val_loss: 0.0010\n",
      "Epoch 709/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0145e-04 - val_loss: 8.1550e-04\n",
      "Epoch 710/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9806e-04 - val_loss: 8.1895e-04\n",
      "Epoch 711/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.6752e-04 - val_loss: 8.2613e-04\n",
      "Epoch 712/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.6498e-04 - val_loss: 7.3639e-04\n",
      "Epoch 713/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.5685e-04 - val_loss: 6.7629e-04\n",
      "Epoch 714/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0306e-04 - val_loss: 7.4817e-04\n",
      "Epoch 715/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6661e-04 - val_loss: 7.2584e-04\n",
      "Epoch 716/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.4891e-04 - val_loss: 7.1836e-04\n",
      "Epoch 717/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4621e-04 - val_loss: 7.4632e-04\n",
      "Epoch 718/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0473e-04 - val_loss: 7.4927e-04\n",
      "Epoch 719/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5460e-04 - val_loss: 6.9123e-04\n",
      "Epoch 720/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.7894e-04 - val_loss: 7.9258e-04\n",
      "Epoch 721/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4877e-04 - val_loss: 6.9894e-04\n",
      "Epoch 722/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.7660e-04 - val_loss: 7.6084e-04\n",
      "Epoch 723/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.9157e-04 - val_loss: 8.1611e-04\n",
      "Epoch 724/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.1891e-04 - val_loss: 7.5854e-04\n",
      "Epoch 725/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1340e-04 - val_loss: 8.3128e-04\n",
      "Epoch 726/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2392e-04 - val_loss: 7.8669e-04\n",
      "Epoch 727/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.7364e-04 - val_loss: 7.1112e-04\n",
      "Epoch 728/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4719e-04 - val_loss: 6.6997e-04\n",
      "Epoch 729/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.8524e-04 - val_loss: 0.0013\n",
      "Epoch 730/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9634e-04 - val_loss: 0.0015\n",
      "Epoch 731/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0685e-04 - val_loss: 9.1503e-04\n",
      "Epoch 732/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.8842e-04 - val_loss: 7.5304e-04\n",
      "Epoch 733/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5420e-04 - val_loss: 6.6563e-04\n",
      "Epoch 734/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.4539e-04 - val_loss: 7.2262e-04\n",
      "Epoch 735/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0272e-04 - val_loss: 6.9282e-04\n",
      "Epoch 736/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8341e-04 - val_loss: 6.5985e-04\n",
      "Epoch 737/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3465e-04 - val_loss: 6.5897e-04\n",
      "Epoch 738/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2650e-04 - val_loss: 6.5791e-04\n",
      "Epoch 739/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0435e-04 - val_loss: 9.0466e-04\n",
      "Epoch 740/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0204e-04 - val_loss: 7.6745e-04\n",
      "Epoch 741/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8645e-04 - val_loss: 9.2785e-04\n",
      "Epoch 742/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0604e-04 - val_loss: 8.9388e-04\n",
      "Epoch 743/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.3556e-04 - val_loss: 8.5638e-04\n",
      "Epoch 744/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8493e-04 - val_loss: 7.3043e-04\n",
      "Epoch 745/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6359e-04 - val_loss: 7.6624e-04\n",
      "Epoch 746/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.4593e-04 - val_loss: 7.0929e-04\n",
      "Epoch 747/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.4460e-04 - val_loss: 6.8915e-04\n",
      "Epoch 748/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.8244e-04 - val_loss: 6.8033e-04\n",
      "Epoch 749/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.8269e-04 - val_loss: 6.4514e-04\n",
      "Epoch 750/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9399e-04 - val_loss: 7.0397e-04\n",
      "Epoch 751/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.2693e-04 - val_loss: 7.1198e-04\n",
      "Epoch 752/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.0981e-04 - val_loss: 8.9557e-04\n",
      "Epoch 753/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.5732e-04 - val_loss: 8.1815e-04\n",
      "Epoch 754/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9138e-04 - val_loss: 8.8010e-04\n",
      "Epoch 755/1000\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 4.2510e-04 - val_loss: 8.1826e-04\n",
      "Epoch 756/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8729e-04 - val_loss: 8.2489e-04\n",
      "Epoch 757/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.0968e-04 - val_loss: 8.1041e-04\n",
      "Epoch 758/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.4767e-04 - val_loss: 7.6678e-04\n",
      "Epoch 759/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5572e-04 - val_loss: 7.5835e-04\n",
      "Epoch 760/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.6264e-04 - val_loss: 6.9632e-04\n",
      "Epoch 761/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6993e-04 - val_loss: 7.5239e-04\n",
      "Epoch 762/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5568e-04 - val_loss: 7.9048e-04\n",
      "Epoch 763/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8031e-04 - val_loss: 6.8160e-04\n",
      "Epoch 764/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8413e-04 - val_loss: 7.0340e-04\n",
      "Epoch 765/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.0013e-04 - val_loss: 7.5660e-04\n",
      "Epoch 766/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 5.1104e-04 - val_loss: 7.1613e-04\n",
      "Epoch 767/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6963e-04 - val_loss: 9.5840e-04\n",
      "Epoch 768/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8340e-04 - val_loss: 7.8748e-04\n",
      "Epoch 769/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5671e-04 - val_loss: 7.6528e-04\n",
      "Epoch 770/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0980e-04 - val_loss: 8.3506e-04\n",
      "Epoch 771/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.9479e-04 - val_loss: 7.5196e-04\n",
      "Epoch 772/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6042e-04 - val_loss: 0.0011\n",
      "Epoch 773/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.4812e-04 - val_loss: 0.0012\n",
      "Epoch 774/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.6227e-04 - val_loss: 0.0011\n",
      "Epoch 775/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0898e-04 - val_loss: 0.0011\n",
      "Epoch 776/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 5.2639e-04 - val_loss: 0.0012\n",
      "Epoch 777/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.8906e-04 - val_loss: 0.0011\n",
      "Epoch 778/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6112e-04 - val_loss: 9.9399e-04\n",
      "Epoch 779/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.7716e-04 - val_loss: 0.0012\n",
      "Epoch 780/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.8057e-04 - val_loss: 0.0012\n",
      "Epoch 781/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.7495e-04 - val_loss: 8.9125e-04\n",
      "Epoch 782/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5409e-04 - val_loss: 8.5532e-04\n",
      "Epoch 783/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.9879e-04 - val_loss: 7.8849e-04\n",
      "Epoch 784/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8277e-04 - val_loss: 7.6240e-04\n",
      "Epoch 785/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.2110e-04 - val_loss: 6.3544e-04\n",
      "Epoch 786/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8036e-04 - val_loss: 0.0019\n",
      "Epoch 787/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.1509e-04 - val_loss: 7.3016e-04\n",
      "Epoch 788/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0595e-04 - val_loss: 7.6361e-04\n",
      "Epoch 789/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 5.0796e-04 - val_loss: 7.5997e-04\n",
      "Epoch 790/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.5079e-04 - val_loss: 7.3050e-04\n",
      "Epoch 791/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.3384e-04 - val_loss: 7.6696e-04\n",
      "Epoch 792/1000\n",
      "7/7 [==============================] - 0s 68ms/step - loss: 4.5316e-04 - val_loss: 7.3566e-04\n",
      "Epoch 793/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8449e-04 - val_loss: 6.7334e-04\n",
      "Epoch 794/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.4291e-04 - val_loss: 6.7654e-04\n",
      "Epoch 795/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.3395e-04 - val_loss: 6.5771e-04\n",
      "Epoch 796/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.2926e-04 - val_loss: 6.4125e-04\n",
      "Epoch 797/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.6855e-04 - val_loss: 6.3286e-04\n",
      "Epoch 798/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.8473e-04 - val_loss: 6.3523e-04\n",
      "Epoch 799/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.7217e-04 - val_loss: 7.6923e-04\n",
      "Epoch 800/1000\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 4.3497e-04\n",
      "Epoch 00800: saving model to saved_models/latent16/cp-0800.h5\n",
      "7/7 [==============================] - 1s 99ms/step - loss: 4.3891e-04 - val_loss: 6.3340e-04\n",
      "Epoch 801/1000\n",
      "7/7 [==============================] - 0s 70ms/step - loss: 4.5533e-04 - val_loss: 6.3095e-04\n",
      "Epoch 802/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.7441e-04 - val_loss: 5.8409e-04\n",
      "Epoch 803/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.3933e-04 - val_loss: 7.2301e-04\n",
      "Epoch 804/1000\n",
      "7/7 [==============================] - 0s 69ms/step - loss: 4.8285e-04 - val_loss: 6.3780e-04\n",
      "Epoch 805/1000\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 4.9666e-04Restoring model weights from the end of the best epoch.\n",
      "7/7 [==============================] - 0s 71ms/step - loss: 5.0125e-04 - val_loss: 6.4686e-04\n",
      "Epoch 00805: early stopping\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Train VAE model with callbacks \"\"\"\n",
    "history = ae.fit(trainX, trainX, \n",
    "                  batch_size = batch_size, \n",
    "                  epochs = epochs, \n",
    "                  callbacks=[initial_checkpoint, checkpoint, EarlyStoppingAtMinLoss()],\n",
    "                  #callbacks=[initial_checkpoint, checkpoint],\n",
    "                  shuffle=True,\n",
    "                  validation_data=(valX, valX)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size: 7.0\n"
     ]
    }
   ],
   "source": [
    "# In this GPU implementation, it shows the number of batches/iterations for one epoch (and not the training samples), which is:\n",
    "print (\"Step size:\", np.ceil(trainX.shape[0]/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Save the entire model \"\"\"\n",
    "# Save notes about hyperparameters used:\n",
    "with open(f'{SAVE_FOLDER}/notes.txt', 'w') as f:\n",
    "    f.write(f'Epochs: {epochs} \\n')\n",
    "    f.write(f'Batch size: {batch_size} \\n')\n",
    "    f.write(f'Latent dimension: {latent_dim} \\n')\n",
    "    f.write(f'Filter sizes: {filters} \\n')\n",
    "    f.write(f'img_width: {img_width} \\n')\n",
    "    f.write(f'img_height: {img_height} \\n')\n",
    "    f.write(f'num_channels: {num_channels}')\n",
    "    f.close()\n",
    "\n",
    "# Save encoder weights:\n",
    "encoder.save_weights(f'{SAVE_FOLDER}/ENCODER_WEIGHTS.h5')\n",
    "\n",
    "# Save the total AE model, i.e. its weights:\n",
    "ae.save_weights(f'{SAVE_FOLDER}/AE_WEIGHTS.h5')\n",
    "\n",
    "# Save the history at each epochs (cost of train and validation sets):\n",
    "np.save(f'{SAVE_FOLDER}/HISTORY.npy', history.history)\n",
    "\n",
    "# Save exact training, validation and testing data set (as numpy arrays):\n",
    "np.save(f'{SAVE_FOLDER}/trainX.npy', trainX)\n",
    "np.save(f'{SAVE_FOLDER}/valX.npy', valX)\n",
    "np.save(f'{SAVE_FOLDER}/testAllX.npy', testAllX)\n",
    "np.save(f'{SAVE_FOLDER}/testAllY.npy', testAllY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate training process\n",
    "\n",
    "Now that the training process is complete, lets evaluate the average loss of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyUAAAGQCAYAAACwDM9wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAB4F0lEQVR4nO3deXgT1foH8O9k674vbEUoSwp0gbLI0qpQUBRENsGiosCV5V65XhEtuHARL4vFjZ+oCCooAlVEKLJ4UUAUqIAgwgWRTZAiS7e0pVvSJuf3x5CUkNI1bZL6/TxPnzYnZ2bOvEmTeeecMyMJIQSIiIiIiIgcROHoBhARERER0V8bkxIiIiIiInIoJiVERERERORQTEqIiIiIiMihmJQQEREREZFDMSkhIiIiIiKHYlJCRERUQ+vXr0dERAT279/v6KY0mJkzZyIiIqLWy1+8eBERERFYvHixHVtFRI2FytENICKyl7y8PNxxxx3Q6/VITk7GsGHDHN0kp7d//3489thjSEpKwt/+9jdHN6daLl68iP79+1seS5IELy8vBAcHo1OnTrjnnntw9913Q6VqvF9xixcvxjvvvFOtusOHD8err75azy0iIqqbxvuJTUR/OZs2bYLBYEBYWBi+/PJLJiWNXFxcHIYOHQoAKCoqQnp6Onbt2oWtW7ciMjIS77zzDpo3b14v2x46dCgGDx4MtVpdL+uvyt13343bbrvNqmzBggUAgOeff96q/OZ6tfWf//wHc+bMqfXyLVq0wNGjR6FUKu3SHiJqXJiUEFGjsW7dOvTs2RP9+/fH/PnzkZ6ejpYtWzqkLUIIFBUVwcvLyyHb/yto3bq1JSkxS0pKwscff4wFCxZg8uTJ2LBhg117TAoKCuDt7Q2lUunQg+sOHTqgQ4cOVmX/93//BwA2MbmZ0WiEwWCAh4dHjbZZ1wRMkiS4ubnVaR1E1HhxTgkRNQrHjx/HiRMnMHz4cNx///1QqVRYt26d5Xmj0Yj4+HgMHz68wuU/++wzREREYPv27ZYyg8GA999/H4MHD0Z0dDS6d++OKVOm4Ndff7Vadv/+/YiIiMD69euxevVqDBo0CNHR0Vi+fDkA4OjRo5g5cyYGDhyIzp07IzY2FomJifj2228rbMuBAwfw0EMPISYmBnFxcZg7dy5Onz5d4Xh8IQTWrFmDESNGWNY9duxY7Nu3r1ZxrMxPP/2E8ePHo1u3boiJicHw4cPxxRdf2NQ7ffo0nnrqKdxxxx2IiopCXFwcxo4di127dlnq6PV6LF682BKT7t27Y8iQIUhOTq5zO8eNG4chQ4bg1KlT2LJli6V88eLFiIiIwMWLF22WSUhIwNixY63KIiIiMHPmTPz4448YM2YMYmNj8fe//x1AxXNKzGU//vgjPvroIwwYMABRUVEYOHAgNmzYYLNNo9GId999F/369UN0dDSGDBmCrVu3VtrOmjK3KS0tDe+++y4GDBiAmJgYfP311wCAPXv24Omnn0b//v0RExOD7t27Y8KECThw4IDNuiqaU2Iuu3btGmbPno3evXsjOjoaiYmJOHLkiFXdiuaU3Fj23XffYeTIkYiOjkZ8fDySk5NRVlZm045t27bhgQceQHR0NPr27Yt33nkHaWlplv9BInJN7CkhokZh3bp18PT0xD333ANPT0/07dsXqamp+Ne//gWFQgGlUokHHngAH330EU6fPo327dtbLZ+amoqAgADcddddAIDS0lL87W9/w+HDhzF06FA88sgjKCgowNq1azFmzBisWrUK0dHRVuv45JNPkJubi1GjRiEkJARNmzYFAHz77bf4/fffce+996JFixbIzc3Fhg0bMHXqVLz++usYMmSIZR0HDx7EhAkT4Ofnh0mTJsHHxwdff/01fv755wr3+7nnnsOWLVswcOBAjBgxAgaDAZs2bcKECROwePFiq7kXdbFz505MnToVwcHBGD9+PLy9vbFlyxa89NJLuHjxIqZNmwYA0Ol0ePzxxwEAiYmJaN68OXQ6HY4dO4YjR46gb9++AIA5c+ZYhtjFxsbCaDTi/Pnzdps4PmrUKGzatAnff/99lT0HlTl27Bi2bduG0aNH3zKhvdlbb72FkpISPPTQQ9BoNEhJScHMmTNx2223oVu3bpZ6r7zyCj777DP07NkTEyZMQE5ODubMmYMWLVrUur23Yj7AHz16NLy8vBAeHg4A2LBhA/Ly8jBs2DA0bdoUV69exRdffIFx48Zh5cqV6N69e7XW/7e//Q2BgYF48sknkZubixUrVmDSpEnYsWMHvL29q1z++++/x5o1a5CYmIiRI0dix44dWL58Ofz8/DBlyhRLva1bt+KZZ57BbbfdhqlTp0KpVCI1NRU7d+6sXWCIyHkIIiIXV1JSIrp37y5mzJhhKfv222+FVqsVu3btspSdOnVKaLVakZycbLX8H3/8IbRarfjPf/5jKVuxYoXQarXihx9+sKp77do1cdddd4lHH33UUrZv3z6h1WpFjx49RFZWlk37CgsLbcqKiorEPffcI+677z6r8pEjR4qoqChx4cIFS5nBYBAPPfSQ0Gq14u2337aUf/PNN0Kr1YrPPvvMah2lpaVi+PDhol+/fsJkMtls+0bmtn/44Ye3rFNWVib69u0runXrJq5cuWIp1+v14qGHHhIdOnQQ586dE0IIsX37dqHVasWWLVsq3W6PHj3EE088UWmdW0lPTxdarVbMmTPnlnV0Op3QarVi+PDhlrK3335baLVakZ6eblO/X79+Vq+pEEJotVqh1WrF3r17bep/+eWXQqvVin379tmUDR06VOj1ekv5lStXRGRkpJg2bZqlzPxenDBhgjAajZby3377TXTo0OGW7axMv379RL9+/Sps5z333COKiopslqnovZmZmSluv/12m9dnxowZQqvVVlg2e/Zsq/KtW7cKrVYrUlJSLGXm1+3G97C5rHPnzlb7azKZxODBg0VcXJylrLS0VMTHx4vevXuL3NxcS3lBQYFISEgQWq1WfPnllxWFhohcAIdvEZHL++abb5Cfn281sf2uu+5CYGAgvvzyS0tZ+/btERkZiU2bNsFkMlnKU1NTAcBq+a+++gpt2rRBZGQkcnJyLD8GgwF9+vTBoUOHUFJSYtWOoUOHIigoyKZ9np6elr+Li4uh0+lQXFyMXr164ezZsygoKAAAZGVl4X//+x/69+9vNRdGrVbjscces1nvV199BS8vLwwYMMCqjfn5+UhISMCff/6J8+fPVyuGlTl+/DguXbqEkSNHokmTJpZyjUaDJ554AiaTCTt27AAA+Pj4AAB2795t2a+KeHt748yZMzh16lSd23er9QOotA3V0aFDB/Tp06dGyzz88MPQaDSWx02aNEF4eLjVa/Hdd98BAB577DEoFOVfxREREYiPj69TmysyZsyYCueQ3PjeLCwshE6ng0KhQOfOnXH06NFqr3/cuHFWj3v16gUA+OOPP6q1fP/+/REWFmZ5LEkSevbsiczMTBQWFgKQ34cZGRkYPnw4/Pz8LHW9vLyQmJhY7bYSkXPi8C0icnnr1q1DYGAgmjZtanUQFBcXh//+97/IyclBYGAgAPnyqHPnzkVaWhri4+MhhMBXX32F9u3bIyoqyrLs2bNnUVJSgt69e99yuzqdDs2aNbM8bt26dYX1srOzsWjRIuzYsQPZ2dk2z+fn58Pb29syh8A8tOZGbdq0sSk7e/YsCgsLKz1ozs7OrnB9NWFuV7t27WyeMw+DS09PBwDcfvvtGDZsGNavX49NmzYhKioKffr0waBBg6yWf+GFF5CUlIQhQ4agZcuW6NmzJ/r164eEhASrg/TaMicj1Rk6VJlbvaaVqejiCv7+/vjzzz8tj80xreh1DQ8Pxw8//FDj7VbmVu+BCxcu4K233sKePXuQn59v9ZwkSdVe/837HBAQAADIzc2t1fKAHDPzOry8vCr9/6jre5yIHI9JCRG5tPT0dOzfvx9CCAwcOLDCOl999ZXlTO7gwYORnJyM1NRUxMfH49ChQ0hPT8ezzz5rtYwQAlqt1ubyqjcyJzpmFZ2JFkJgwoQJOHv2LB577DFERUXBx8cHSqUSX375JTZv3mzVa1MTQggEBgbijTfeuGWdm+fONITk5GT87W9/ww8//ICDBw9ixYoVeP/99/HCCy/g0UcfBQAMGDAAO3fuxPfff4+ffvoJaWlpWLduHbp3744VK1ZY9TTUxsmTJwFYH6xWdpBd0YRqoOLXtCr2SKrszd3d3aassLAQjzzyCIqLi/H4449Dq9XCy8sLCoUCS5curdHFEm51JTIhRJ2Wr8k6iMi1MSkhIpe2fv16CCEwd+5cy9ChGy1atAhffvmlJSkJDAzEnXfeie3bt6OwsBCpqalQKBR44IEHrJZr1aoVdDodevXqVaeDzJMnT+K3337Dk08+iaeeesrquZuvXGWe4Hzu3Dmb9fz+++82Za1atcL58+fRuXPner30sHlYzZkzZ2yeM5fdfKZbq9VCq9XiiSeeQH5+PkaNGoU33ngDjzzyiCU58Pf3x9ChQzF06FAIIfD666/jww8/xI4dO3DffffVqc3m2JovXADAMuQnLy/PaqiQXq9HZmYmWrVqVadt1oR5+7///rtN7Cp6/evDjz/+iIyMDMyfPx8jR460em7RokUN0oaaqOz/o6FiRkT1x/lO5xARVZPJZMKGDRug1WoxatQo3HvvvTY/999/P06dOmU1Pn748OEoLi7GV199hf/+97/o06eP1VwJQJ5fkpmZiRUrVlS47aysrGq10ZzQ3Hy299SpUzaXBA4JCUFUVBR27NhhGQ4FyFcCW7lypc26hw0bBpPJhDfffLNObaxKZGQkmjdvjvXr1yMzM9OqXR999BEkSbJc5Ss3N9em58fX1xdhYWEoLi6GXq+H0WiscKhQp06dAMhJQ1188skn2LRpEyIiIjBo0CBLuXkoVlpamlX9jz/+uNa9VbXVr18/AMDKlSuttn3y5Ens2bOnQdpg7p24+b25Z88em8v5OoOoqCiEhIRYrhhmVlhYiM8++8yBLSMie2BPCRG5rD179uDy5ct48MEHb1nnnnvuweLFi7Fu3TrExMQAkM+e+/v74/XXX0dBQUGFl3p97LHHkJaWhoULF2Lfvn3o1asXvL29cenSJezbtw8ajQaffvpplW1s27Yt2rdvjw8//BAlJSUIDw/HuXPn8Pnnn0Or1eL48eNW9WfMmIEJEyYgMTERY8aMsVwSuLS0FID1EKR7770XI0aMwKpVq3D8+HH069cPAQEBuHLlCn755Rf88ccflgnoVfnxxx+h1+ttygMCAjBmzBjMmjULU6dOxYMPPmi5rOzXX3+NX375BVOmTLEc8KempuKTTz7BgAED0KpVK6hUKvz000/Ys2cP7rvvPri7uyM/Px/x8fFISEhAp06dEBgYiIsXLyIlJQV+fn6WA/aqnD9/Hhs3bgQAlJSU4MKFC9i1axfOnDmDyMhIvPfee1Y3TuzTpw/Cw8Px9ttvIzc3F2FhYTh06BCOHDlimQPRUNq3b4+HHnoIn3/+OcaNG4e7774bOTk5WLNmDTp27Ijjx4/XaE5HbXTr1g0hISFITk7Gn3/+iaZNm+LEiRPYuHEjtFptvV2EoLZUKhVmzJiBZ599FqNGjcKDDz4IpVKJDRs2wN/fHxcvXqz3mBFR/WFSQkQuy3xzxLvvvvuWdbRaLVq3bo2tW7fihRdegLu7OzQaDe6//36sWrUK3t7eGDBggM1yarUaS5cuxZo1a7Bx40bLDd9CQ0MRHR1d7XtWKJVKLF26FMnJydiwYQOKi4vRvn17JCcn47fffrNJSm6//XZ88MEHeOutt7B06VL4+vrivvvuw5AhQzB69GibO2IvWLAAPXv2xNq1a7F06VKUlpYiJCQEnTp1wvTp06vVRkC+Wtbu3bttysPDwzFmzBgkJCTg448/xpIlS/DRRx+htLQUbdu2xdy5czFq1ChL/Z49e+LEiRPYtWsXMjMzoVAoEBYWhhkzZljmk7i7u+Pxxx/Hjz/+iB9//BGFhYUIDQ1FQkICJk+ebNNrdSt79+7F3r17IUkSPD09Lfs9depU3H333TZ3clcqlViyZAnmzp2LVatWQa1WIy4uDqtWrcKYMWOqHSt7mT17NkJDQ7Fu3TokJycjPDwcs2fPxv/+9z8cP368wnkg9uTr64sPP/wQr732GlatWoWysjJERUXhgw8+wLp165wuKQGAIUOGQKVS4b333sPbb7+N4OBgPPjgg4iIiMDUqVN5x3giFyYJziAjInJ627Ztw1NPPYU333wTgwcPdnRzqB5NmTIF+/btw6FDhyqdAE7lli9fjuTkZHz++efo0qWLo5tDRLXAOSVERE5ECGEzjKq0tBQrVqyASqXC7bff7qCWkb3dfJ8bAPjtt9/www8/oFevXkxIKmAwGGA0Gq3KCgsLsXr1avj7+1vmJRGR6+HwLSIiJ2IwGNCvXz8MGTIE4eHhyM3NxdatW3Hy5ElMnDgRISEhjm4i2cmGDRuwceNGy40+f//9d6xduxZqtdrmSm0kS09Px8SJEzF48GCEhYUhMzMTGzZswMWLF/Hyyy/X+VLSROQ4TEqIiJyISqXCXXfdhR07diAzMxNCCISHh+Pf//43HnnkEUc3j+woMjIS27dvx6effoq8vDx4eXmhZ8+emDp1Ks/430JgYCC6dOmCTZs2ITs7GyqVClqtFtOnT7e60hoRuR7OKSEiIiIiIofinBIiIiIiInIoDt+qBpPJBKPRsR1KSqXk8DY0BoyjfTCO9sE42gfjaB+Mo30wjvbBONqHM8ZRra74Ih5MSqrBaBTIzS1yaBv8/T0d3obGgHG0D8bRPhhH+2Ac7YNxtA/G0T4YR/twxjiGhPhUWM7hW0RERERE5FBMSoiIiIiIyKGYlBARERERkUMxKSEiIiIiIodiUkJERERERA7FpISIiIiIiByKlwQmIiIiomorLi5EQUEujMayetvG1asShHCu+2u4ooaKo0KhhEqlgY+PP9RqTa3WwaSEiIiIiKqluLgQ167p4O8fArVaA0mS6mU7SqUCRqOpXtb9V9IQcRRCwGQyQq8vhk6XAR+fAHh4eNV4PUxKiIiIiKhaCgpy4e8fAo3GzdFNISchSRKUShU8PX2gUqmRn59Tq6SEc0qIiIiIqFqMxrJaD8+hxk+tdkNZWWmtlmVSQkRERETVVl9Dtsj11eW9weFbLqCgALh2DfDxcXRLiIiIiIjsjz0lLmDxYg3uvpsvFRERERE1TjzSdQHXrknQ6RzdCiIiIqLG5YcfduGzz1bZfb3z5r2MBx8cYvf1NmZMSlyAQgEYjY5uBREREVHjsnv3Lnz++Rq7r3fcuCcwf/5rdl9vY8Y5JS5AoQBMvFQ3ERERkUMYDAZoNNW/6liLFmH12JrGiUmJC2BSQkRERGRf8+a9jK+/3gwAiI/vDgBo2rQZXnhhNp56agrmzVuIffvSsHv3LpSVleG//92FixfTsWLFMhw9egTZ2dkICgpGz569MGnSk/D19bVa9+HDh7Bu3SYAwOXLlzBq1AN49tnnkZWViU2bNkCv1yMmJhbPPjsToaFNGnr3nQ6TEhegUAgO3yIiIiKn9PnnKqSkqO26TkmSIISodv0xY0rx0ENlNdrGuHFPIDdXhxMnfsWrr74JANBo1CgoKAAAvPXWa+jVqw9eeukVGAwGAEBWViZCQ5viqaf6w8fHF5cu/YmVK1fg9Ol/YenSFVVuc9WqjxEVFYOZM/+N3Fwd3nnnLbzyyiy8886yGrW9MWJS4gKUSvaUEBEREdlTixZh8PcPgFqtRlRUtKX8558PAgA6dozEzJmzrJbp0qUrunTpankcFRWDFi1a4sknn8CpU79Bq+1Q6TabNm2Gl1+eZ3ms0+nw3nv/h6ysTAQHh9hjt1wWkxIXwInuRERE5Kweeqisxr0UVVEqFTAaHXtG9s47+9qUlZaWIiXlU/z3v1tw5coVGAx6y3MXLvxRZVLSu3ec1eO2bdsBAK5cucKkxNENoKrJc0p491QiIiKihhIcHGxT9v777+DLLz/HuHFPIDq6Mzw9PZGRkYEXX3zOMsSrMr6+flaP1Wp52NuNyc1fFZMSF6C4fuFmIQCJuQkRERFRA7A96Nqx4xvce+9gjBv3hKWsuLi4IRvVaPE+JS7AnJRwCBcRERGR/ajVauj11e+lKCkpgUplfU5/y5av7N2svySH9JSsXr0aH330ETIzM9G+fXu88MIL6N69e4V1MzIykJycjOPHj+OPP/7A0KFD8eqrr1rVGTt2LA4cOGCzbLt27bBlyxYAwPr16/H888/b1Dl69Cjc3NzssFf1R6mUf3OyOxEREZH9tG7dBvn5G7Bhwzp06NARGk3lx4Q9e/bG119vRps27RAW1hLff78Tx44dbaDWNm4NnpRs3boV8+fPx+zZs9GtWzesWbMGEydOxJYtW9C8eXOb+gaDAQEBAZg0aRLWrl1b4ToXL16M0tJSq2WGDBmC++67z6qeh4cHvv32W6syZ09IAPaUEBEREdWHIUOG4fjx/2Hp0ndRUHDNcp+SW5k2LQmAwLJl7wGQJ66//PI8TJz4eAO1uPFq8KRkxYoVGD58OEaPHg0AmDVrFnbv3o2UlBRMnz7dpn5YWBheeuklAMC2bdsqXKe/v7/V46+++golJSUYOXKkVbkkSQgJcb0rGygU8nW62VNCREREZD8eHh6YM2e+TfmePQcrrO/v7485cxZUWf/FF1+2etysWfMK19m1a/dbbuuvpkHnlBgMBhw/fhxxcdaXQ4uLi8Phw4fttp0vvvgCd9xxB5o1a2ZVXlJSgn79+uHOO+/E5MmT8euvv9ptm/XJ3FPCpISIiIiIGqMG7SnR6XQwGo02l1gLCgpCWlqaXbZx7tw5HDhwAO+++65VeXh4OObPn48OHTqgsLAQK1euxJgxY7Bx40a0bt260nUqlRL8/T3t0r7a8PaWr/7g4+OJmzqFqIaUSoVDX8vGgnG0D8bRPhhH+2Ac7aOxx/HqVQlKZcOc026o7TR2DR1HSardcXOjuyTw2rVrERISgr59+1qVx8bGIjY21urxsGHDsGrVKsvwsFsxGgVyc4vqo7nVoterAbhDp3NcGxoLf39Ph76WjQXjaB+Mo30wjvbBONpHY4+jEKJBbmroDDdPbAwcEUchKj9uDgnxqbC8QVOngIAAKJVKZGVlWZVnZ2fbZa6HwWBAamoqRo4caXO5tpsplUpERUXh/Pnzdd5ufSuf6M6blBARERFR49OgSYlGo0FkZKTNUK20tDSrXoza2r59O3Q6HR588MEq6wohcPLkSZeY+M45JURERETUmDX48K3x48cjKSkJMTEx6Nq1K1JSUpCRkYHExEQAQFJSEgBg4cKFlmVOnDgBACgoKIAkSThx4gTUajXatWtnte61a9eid+/eaNmypc1233nnHXTu3BmtW7dGQUEBVq5ciZMnT+Lll1+upz21HyYlRERERNSYNXhSMmjQIOh0OixZsgQZGRnQarVYtmwZWrRoAQC4fPmyzTLDhg2zevzdd9+hRYsW2Llzp6UsPT0d+/btw5tvvlnhdvPz8/Hvf/8bmZmZ8PHxQadOnbBq1SrExMTYb+fqCW+eSERERESNmSSEEI5uhLMrLTU6dNLamjUqPP20B37+uQBhYXy56qKxT0BsKIyjfTCO9sE42gfjaB+NPY5XrvyBpk1b1ft2ONHdPhwRx6reI04x0Z1qh3d0JyIiIqLGjEmJC+CcEiIiIiJqzJiUuAAmJURERETO6/LlS4iP746tWzdZyubNexkPPjikymW3bt2E+PjuuHz5Uo22ee3aNXz00VKcPPmbzXNTp07C1KmTarQ+R2t0N09sjMonuksAOKeEiIiIyNmNG/cERo1KrLf1FxRcw4oVHyA0tAkiIjpYPTd9+sx62259YVLiAthTQkRERORaWrQIc9i2w8PbOGzbtcXhWy6AE92JiIiI7Gvnzu2Ij++OM2dO2zz37LNP4fHHxwAAvvzyc0yePB733ZeAe+/ti0mTxiEtbU+V669o+Naff17Ec8/9C/37x+H++wdg0aLXYTAYbJbdvn0bnnpqCu6/fwDuvvsOjB//ML7+erPl+cuXL2HUqAcAAMnJcxEf391q+FhFw7cuXDiP559/Fvfe2xcJCXGYNGkc9u2zvqH5Rx8tRXx8d6SnX8Bzz/0Ld999B0aOvB8rVnwAUz2fHWdPiQtgTwkRERE5q7NnJZw5Y9/z3AqF4vqw9epp186Etm1rNsQ9Lu4OeHt745tvtqJdu39ZynNysvHTT/sxZco/Acj30BsyZCiaNm0Oo9GIvXt/QFLS03j99bfRq1efam+vtLQU06Y9Cb1ej2eemYGAgEBs3PglfvjhO5u6ly79ib59++PRR8dBkiQcOXIYr776H+j1JRg27EEEBQVj3rzX8OKLz2Hs2PGIi7sTwK17Z7KyMvGPfzwBDw8vTJuWBC8vb6xf/wWSkp5GcvJb6N07zqr+Cy88i0GDHsDo0Q9j797d+OijpQgNbYLBgx+o9v7WFJMSF8CkhIiIiMi+3Nzc0K/fAHz77TZMmfJPKK4fcG3fvg0AcPfd9wIApk592rKMyWRCt249kJ5+Aamp62qUlHz99WZcuvQn3n9/BaKiogEAvXr1wWOP2c47eeyxCVbbjI3thuzsLGzY8CWGDXsQGo0GWm0EAKB58xaW9d3KZ5+txrVr1/D++ysQFtYSANC7dxwefXQUPvjgPZukJDHxUUsC0qNHT/z880/Yvn0bk5K/OqVSzvyZlBAREZGzadtWoG1b+44xVypFg9z07957B2PTplQcOvQTevToCQD473+3olu3HggODgYA/PbbCSxfvhQnTvyK3FwdzPcdv+22mt1E8tixowgNbWKVQCgUCiQkDMDy5cus6qanX8CHH76PI0cOIycn2zJ0SqPR1Go/jxz5GZ06RVkSEgBQKpUYMGAgPv74QxQWFsDLy9vyXJ8+8VbLh4e3xenTJ2u17epiUuICOKeEiIiIyP5iYrqgWbPm2LZtK3r06Inz58/h1Knf8O9//wcAcPXqFTz99N/RunUbPP30c2jSpClUKiU++OB9/PHHuRptKzs7G4GBQTblgYGBVo+LioowbdqTcHd3x5QpU9GiRRjUajU2bFiHLVu+qtV+5ufno337CJvyoKAgCCFw7do1q6TEx8fXqp5Go6lw7os9MSlxARy+RURERGR/kiThnnvuw9q1KXj22eexbdtWeHh44s47+wEA9u//EQUFBXjllQUIDW1iWU6vL6nxtoKCgnDu3Fmb8pycHKvHx48fxZUrl/Huux+ic+culnJjHc5O+/r6Iicn26Y8OzsbkiTBx8en1uu2F159ywWUJyXVn/BFRERERFUbOHAQiouL8P33O/HNN1/jrrv6wd3dHQBQUiInHypV+Xn8Cxf+wP/+d6TG24mKikFGxlUcO/Y/S5nJZMLOndut6lW0zfz8fOzZ871VPbVaHspVnQSpS5duOH78f1Y3aDQajdi581u0bx9h1UviKOwpcQHsKSEiIiKqH7fd1gqdOkXh/fffQWZmBu69d7Dlue7db4dSqcTcubORmPgosrOzrl+JqimEqNmB2X333Y9Vqz7Giy8+h8mTn0RAQABSU79EUVGhVb2oqM7w8vLCm28m429/m4zi4mKsXPkR/Pz8UVBQYKkXGBgIPz8/7NjxDdq2bQ8PDw80a9Ycfn7+Ntt+6KGH8fXXmzBt2pOYMGEyvLy8sGHDF0hPv4CFCxfVaD/qC3tKXED5Hd0d2w4iIiKixmjgwEHIzMxASEgounbtbilv06Yt/v3vubhy5TJmznwGq1evxJQpU9GlS2yNt6FWq/HWW++ifXst3njjVcyb9zKaNWthdaUtAAgICMD8+a/DZDLipZdmYOnSd3D//cNwzz33WdVTKBSYMWMWrl27hqef/geeeOIx7N27u8JtBweH4L33PkR4eBu88cYCzJo1A/n5+Vi4cFGNriBWnyRhvoQA3VJpqRG5uUUO2/6PPyoxdKgn1q0rwp13crZ7Xfj7ezr0tWwsGEf7YBztg3G0D8bRPhp7HK9c+QNNm9bsqlO1oVQqGuTqW42dI+JY1XskJKTi+SvsKXEBHL5FRERERI0ZkxIXoFDwPiVERERE1HgxKXEB7CkhIiIiosaMSYkL4ER3IiIiImrMmJS4gPI7uvM+JURERORYvEYS3Upd3htMSlwAh28RERGRM1AqVSgtNTi6GeSkSkv1UKnUtVqWSYkLYFJCREREzsDb2x+5uZkwGPTsMSEAcu+I0ViGwsJryM3NgpeXX63Wwzu6uwAmJUREROQMPDy8AAB5eVkwGsvqbTuSJDHpsYOGiqNCoYRarUFAQCjUak2t1sGkxAVwojsRERE5Cw8PL0tyUl8a+00oG4orxZHDt1yA+T4lRt7MnYiIiIgaISYlLoDDt4iIiIioMWNS4gKYlBARERFRY8akxAUwKSEiIiKixoxJiQson+jOmycSERERUePDpMQFlN/R3bHtICIiIiKqDw5JSlavXo2EhARER0djxIgROHjw4C3rZmRkYPr06bj33nvRsWNHzJw506bO+vXrERERYfOj1+trvV1nwuFbRERERNSYNXhSsnXrVsyfPx9TpkxBamoqYmNjMXHiRFy6dKnC+gaDAQEBAZg0aRI6d+58y/V6eHhgz549Vj9ubm613q4zYVJCRERERI1ZgyclK1aswPDhwzF69Gi0bdsWs2bNQkhICFJSUiqsHxYWhpdeegkjRoyAn9+tb1svSRJCQkKsfuqyXWdivk8JkxIiIiIiaowaNCkxGAw4fvw44uLirMrj4uJw+PDhOq27pKQE/fr1w5133onJkyfj119/bZDtNgTe0Z2IiIiIGjNVQ25Mp9PBaDQiODjYqjwoKAhpaWm1Xm94eDjmz5+PDh06oLCwECtXrsSYMWOwceNGtG7dus7bVSol+Pt71rp9dWUevqXRaODvr3ZYOxoDpVLh0NeysWAc7YNxtA/G0T4YR/tgHO2DcbQPV4pjgyYl9SU2NhaxsbFWj4cNG4ZVq1bhpZdeqvP6jUaB3NyiOq+ntgoLAcAHhYUG5OaWOqwdjYG/v6dDX8vGgnG0D8bRPhhH+2Ac7YNxtA/G0T6cMY4hIT4Vljfo8K2AgAAolUpkZWVZlWdnZ9vMAakLpVKJqKgonD9/vkG3W1/KJ7rzPiVERERE1Pg0aFKi0WgQGRlpM2QqLS3NqqejroQQOHnypCXhaKjt1hfOKSEiIiKixqzBh2+NHz8eSUlJiImJQdeuXZGSkoKMjAwkJiYCAJKSkgAACxcutCxz4sQJAEBBQQEkScKJEyegVqvRrl07AMA777yDzp07o3Xr1igoKMDKlStx8uRJvPzyy9XerjPjJYGJiIiIqDFr8KRk0KBB0Ol0WLJkCTIyMqDVarFs2TK0aNECAHD58mWbZYYNG2b1+LvvvkOLFi2wc+dOAEB+fj7+/e9/IzMzEz4+PujUqRNWrVqFmJiYam/XmfGO7kRERETUmElCCOHoRji70lKjwycJhYb6YPp0PWbMMDi0Ha7OGSd8uSLG0T4YR/tgHO2DcbQPxtE+GEf7cMY4OsVEd6o9hUJw+BYRERERNUpMSlyEUsk5JURERETUODEpcREKBZMSIiIiImqcmJS4CIUCMBp5nxIiIiIianyYlLgI9pQQERERUWPFpMQFHDumgMnEpISIiIiIGicmJS5ACECSgLIyR7eEiIiIiMj+mJS4AG9vAUkC9HpHt4SIiIiIyP6YlLgAHx+5p6SkxNEtISIiIiKyPyYlLsDbW0ChAPR6Xn2LiIiIiBofJiUuwN1dvvqWweDolhARERER2R+TEhehVLKnhIiIiIgaJyYlLkKpZE8JERERETVOTEpchFLJSwITERERUePEpMRFmJMSo9HRLSEiIiIisi8mJS5CqZRvolhU5OiWEBERERHZF5MSF6FSASYTUFTEye5ERERE1LgwKXERKhV7SoiIiIiocWJS4iLYU0JEREREjRWTEhehUgGSBBQXO7olRERERET2xaTERSgUgCRJ7CkhIiIiokaHSYmLUCrlnhLOKSEiIiKixoZJiYuQe0o4p4SIiIiIGh8mJS5C7ikRKC5mUkJEREREjQuTEhdh7ikxGoGSEke3hoiIiIjIfpiUuAi1Wr4kMMB5JURERETUuDApcRFqNSCEPHSL80qIiIiIqDFhUuIi1Gp56BYAzishIiIiokaFSYmLUKnKkxLOKSEiIiKixsQhScnq1auRkJCA6OhojBgxAgcPHrxl3YyMDEyfPh333nsvOnbsiJkzZ9rUWbt2LR5++GH06NED3bt3x9ixY23WuXjxYkRERFj9xMXF2X3f6otaLWA0AhqN4PAtIiIiImpUGjwp2bp1K+bPn48pU6YgNTUVsbGxmDhxIi5dulRhfYPBgICAAEyaNAmdO3eusM7+/fsxaNAgfPLJJ1i7di3Cw8PxxBNP4Pz581b1wsPDsWfPHsvPpk2b7L179UatBkpLJXh4sKeEiIiIiBoXVUNvcMWKFRg+fDhGjx4NAJg1axZ2796NlJQUTJ8+3aZ+WFgYXnrpJQDAtm3bKlznG2+8YfV4zpw52LFjB3bv3o3WrVtbylUqFUJCQuy0Jw1LrQbKygAPD4HiYke3hoiIiIjIfhq0p8RgMOD48eM2w6bi4uJw+PBhu22ntLQUer0evr6+VuXp6emIj49HQkICpk2bhvT0dLtts77JPSWAuztQUsLhW0RERETUeDRoT4lOp4PRaERwcLBVeVBQENLS0uy2nbfeeguenp7o37+/pSwmJgYLFixAmzZtkJOTgyVLliAxMRGbN29GQEBApetTKiX4+3varX214eYmoawMCA11g04nwd9f49D2uCqlUuHw17IxYBztg3G0D8bRPhhH+2Ac7YNxtA9XimODD9+qb5988gk+//xzfPzxx/D29raU33XXXVb1OnfujAEDBiA1NRXjx4+vdJ1Go0BurmPvWKhSecFgkFBaWoK8PCWyskqhanSvXv3z9/d0+GvZGDCO9sE42gfjaB+Mo30wjvbBONqHM8YxJMSnwvIGHb4VEBAApVKJrKwsq/Ls7Gy7zPX4+OOPsWjRIixbtgwxMTGV1vXy8kK7du1sJsM7K/OcEk9PAQB2n1dSXAxs3apCdjaHhhERERFRw2rQpESj0SAyMtJmqFZaWhpiY2PrtO4VK1bg//7v/7Bs2TJ07969yvp6vR7nzp1zmYnvKlX5nBLA/jdQPH1agawsCWfO8NY1RERERNSwGnwA0Pjx45GUlISYmBh07doVKSkpyMjIQGJiIgAgKSkJALBw4ULLMidOnAAAFBQUQJIknDhxAmq1Gu3atQMAfPjhh1i0aBEWLlyI1q1bIzMzEwDg7u4OHx+5iyg5ORn9+vVDs2bNkJOTg/feew9FRUUYPnx4g+17Xcg9JRLc3eWeEnteFthkAk6elJORkycVyMiQ0K9fGW4Y/UZEREREVG8aPCkZNGgQdDodlixZgoyMDGi1WixbtgwtWrQAAFy+fNlmmWHDhlk9/u6779CiRQvs3LkTALBmzRqUlpZi2rRpVvWGDx+OV199FQBw5coVPPPMM8jNzUVAQAC6dOmCtWvXWrbr7NRq699yT4mwy7ovXJBQXCyhVSsT/vhDAZ1Owq5dKtx/f5ld1k9EREREVBmHTJV+5JFH8Mgjj1T43KeffmpTdvLkyUrXZ05OKvPWW29Vr3FOypyMKK6PrrLXnBIhgOPHlfDxEbjzTiN0OiMyMxXYv1+JrCwJwcH2SXyIiIiIiG6FEwhchDkpMZkAd3dht3uV/P67hOxsCTExRkgSEBgIhIeboFIJnD3LtwcRERER1T8edboIzfXbkhgMEjw87NdT8vvvCvj7C7RtW94jotEAAQFAXp59tkFEREREVBkmJS7C3FNSVgZ4eAi7XH3LZAIyMyU0bWqyec7HRyA/n5cHJiIiIqL6x6TERZiTEvNlge3RU5KdLaGsTEJoqO28ER8fgaIiCUZj3bdDRERERFQZJiUuwnz39tJSuafEHnNKrl6V13GrpAQACgrqvBkiIiIiokoxKXER5cO3JLi7A0YjYDDUbZ2XLkkICBDw9LR97vrtXZCXxyFcRERERFS/mJS4CLVa7rkw95QAdbuBYlkZkJGhQLNmtvNJgPKekl27VJzwTkRERET1ikmJi7hxoru7u/x3XSa7Z2RIMJmA5s0rvg+JuzvQvbs8oSQri70lRERERFR/mJS4COuJ7nXvKcnMlBONkJBb3xwxIkLuRSkoYFJCRERERPWHSYmLMN+npLRUsvSU1GWye1aWPJ/EnOxURKkEvLwEkxIiIiIiqldMSlzEzZcEBmrfUyKE3FMSHHzrXhIzb2+Ba9dqtx0iIiIioupgUuIibpxTolAAbm61v4FiQYF8Z/jqJSUcvkVERERE9YtJiYu4sacEADw8at9TkpMjJxkBAVUnJbyJIhERERHVNyYlLqL85olyQuHuLmqdlOh0EiQJ8PevOinx85PrZGezt4SIiIiI6geTEhdx4/AtQJ5XUtuJ7jqdBF9fYUl0KtOkiZyUXLnCpISIiIiI6geTEhdx8/CtuvaUVKeXRN6OPMyLSQkRERER1RcmJS6iojklBkPN53oYDPLE9cDA6iUlANCsmQmZmQpLLw0RERERkT0xKXERN96nBLjxru41W49OV/1J7mZNmwoYjeU3XCQiIiIisicmJS7Cdk6JnFTo9TVLFMxJSXWHbwHyvBKFArh8mUkJEREREdkfkxIXYTunRP5d056S3FwJGo2At3fNtu3vL3gFLiIiIiKqF0xKXER5UiInBh4eck9HTSe75+TUbD6Jmbu7sGybiIiIiMiemJS4iIouCQygRnd1FwLIza3Z0C0zlaq8l4aIiIiIyJ6YlLiIm4dvqVSASlWzywJfuwaUldWup0StBq++RURERET1gkmJi5AkQKkUVolBTW+gmJNjvvJWzbfPnhIiIiIiqi9MSlyIWi3fm8TMw6NmE91zcyVIUu2Gb6nVAmVlnFNCRERERPbHpMSF3DyEytNT1GhOSU6OBD8/AaWydts2mVDjmzUSEREREVWFSYkL0WgEDIbyxx4eokY9JTqdVKObJt5IpZJ/cwgXEREREdkbkxIXotHgpqREHs5VnUTBYAAKC6VaDd0C5OFbACe7ExEREZH9MSlxITfPKfHykhOF6vSWmO/kXpsrbwHsKSEiIiKi+uOQpGT16tVISEhAdHQ0RowYgYMHD96ybkZGBqZPn457770XHTt2xMyZMyust23bNgwaNAhRUVEYNGgQvv32W6vnhRBYvHgx4uPjERMTg7Fjx+L06dN23a/65uZ28/At+Xd15pWUX3mrdkmJRiP/5g0UiYiIiMjeGjwp2bp1K+bPn48pU6YgNTUVsbGxmDhxIi5dulRhfYPBgICAAEyaNAmdO3eusM7hw4cxbdo0DBkyBBs3bsSQIUPwr3/9C0eOHLHU+eCDD7B8+XLMmjUL69atQ2BgIMaPH4+CgoJ62c/6IPeUlD/29JQTjMLCqpfNzZXg5ibg6Vm7bZsnx3P4FhERERHZW7WTko4dO+Lo0aMVPnfs2DF07NixWutZsWIFhg8fjtGjR6Nt27aYNWsWQkJCkJKSUmH9sLAwvPTSSxgxYgT8/PwqrPPJJ5+gZ8+e+Pvf/462bdvi73//O26//XZ88sknAORekpUrV2LSpEkYOHAgtFotkpOTUVhYiM2bN1er3c7Azc32ksBA9XtKattLAsiT7AEO3yIiIiIi+6t2UiLErQ9oTSYTJKnqA2ODwYDjx48jLi7OqjwuLg6HDx+ublNs/PLLLzbrjI+Pt6zz4sWLyMzMtKrj7u6OHj161Gm7DU2tFlZJgUYjl1XVUyIEkJdX+6FbQPmcEvaUEBEREZG9qaqqYDKZLAmJyWSCyWSyer6kpAQ//PADAqpxm3CdTgej0Yjg4GCr8qCgIKSlpdWk3VaysrJs1hkcHIzMzEwAsPyuaLsZGRlVrl+plODvX8txT3aiVCrg5QXo9bBqS2io/Nvf/9bL5uYCGo2EVq1EpfUq4+4OeHpKcHNT13odzkCpVDj8tWwMGEf7YBztg3G0D8bRPhhH+2Ac7cOV4lhpUvLOO+/g3XffBQBIkoQxY8bcsu7DDz9s35Y5EaNRIDe3yKFt8Pf3hEIh3yzxxrZIkhJXr0rIzb11F8bvv0soKlJBrS5Fbm7ttl9WBhQVqaHTGZGba6p6ASfl7+/p8NeyMWAc7YNxtA/G0T4YR/tgHO2DcbQPZ4xjSIhPheWVJiW33347AHno1rvvvosHH3wQTZs2taqj0WjQtm1b9OvXr8pGBAQEQKlUIisry6o8OzsbISEhVS5/K8HBwTbrzMrKsqzT/DsrKwvNmze32u7NvSfOTK0W0Outh8l5ewtkZFQ+dC4nR4JSCdxiSk61qFSAJHFOCRERERHZX5VJiTkxkSQJo0aNQpMmTWq9MY1Gg8jISKSlpeG+++6zlKelpeGee+6p9Xq7dOmCtLQ0PPHEE1brjI2NBSBPlg8JCUFaWhpiYmIAAHq9HgcPHkRSUlKtt9vQ3NxskwIvL3nyu14vP1+RnBz5pomKOl5rzcdHICuLlwQmIiIiIvuqck6J2dSpU23Kzpw5g7Nnz6JLly7VTlbGjx+PpKQkxMTEoGvXrkhJSUFGRgYSExMBwJIkLFy40LLMiRMnAAAFBQWQJAknTpyAWq1Gu3btAACPPfYYHn30USxbtgz9+/fH9u3bsX//fqxZswaAnFA99thjWLp0Kdq0aYPWrVtjyZIl8PT0xP3331/dEDicWo0Ke0oAoKBAvuRvRXJyJLRuXftJ7mZt2pjwyy9KFBQY4e1d59UREREREQGoQVLyyiuvoKysDK+88goA4JtvvsG0adNgNBrh7e2N5cuXW3ohKjNo0CDodDosWbIEGRkZ0Gq1WLZsGVq0aAEAuHz5ss0yw4YNs3r83XffoUWLFti5cycAoGvXrnjzzTexaNEivP3222jZsiXeeustq/uaTJw4EXq9Hq+88gry8vLQuXNnLF++HN4udHR9880TAViSg4ICICjIdplr1+SelKCgus8Dad1aTkouX1agfXvXnVdCRERERM5FEpVd6/cGAwYMwNSpUy0JwpAhQ3DbbbfhqaeeQnJyMtRqNZYuXVqfbXWY0lKjwycJ+ft7YtIkIzZtUuHEifJrAJeVAWvWqNGlixExMbaJwvnzEn74QYXBg8sQFFS33hKjEVi9Wo3YWCOio10zKXHGCV+uiHG0D8bRPhhH+2Ac7YNxtA/G0T6cMY63muhe7VkGmZmZlt6MK1eu4PTp05g8eTIiIiIwduxY/O9//7NPS+mW3Nxsh2+pVPIQrtzciud65ORIUCgAf/+6D99SKuWbKBYVcV4JEREREdlPtZMSd3d3FBXJmdaBAwfg7e2NqKgoAICnpycKq7qDH9XZzTdPNPP3F8jLu3VS4ucnoFTapw0eHkBJiX3WRUREREQE1CApiYyMxOrVq3Hq1CmsWbMGffr0geL65ZwuXrxYp0v6UvVoNHJPyc0D7vz85KTkpvtaQgggK0tCcHDde0nM3N0FiovttjoiIiIiouonJU8//TSOHDmCoUOH4ty5c/jHP/5heW779u3VmuROdaPRyL/LbrpPor+/gMkE5OVZl+fmypPcmzSx3/wPd3egpITDt4iIiIjIfqp99a2YmBh89913+P3339G6dWurq1Y99NBDaNWqVb00kMppNHKPh14vXx7YzNwTkpWlQEBAeQJy9aqcc4aG2q+nxMND4PJlJiVEREREZD/VTkoAee6IeR7Jjfr27Wuv9lAlzDdHvHleiZ+fnLBkZkpo3768/MoVCZ6ewq73FPHwkHtfjEbYbZ4KEREREf211SgpOXnyJN59910cOHAA+fn58PX1Rc+ePfHkk09Cq9XWVxvpOnPviMEgAbDu/QgNlZMSM5MJuHzZPjdNvJG7u/y7uBi8gSIRERER2UW1k5KjR49i7NixcHd3R0JCAoKDg5GVlYWdO3fi+++/x6pVqyrsRSH7Md+x/eYbKAJAkyYCFy8qcO0a4OMj95KUlkoICzPatQ0eHnIbiooky93kiYiIiIjqotpJyZtvvon27dvj448/tppPUlBQgPHjx+PNN9/E8uXL66WRJCvvKbF9rlUrEw4dUuL8eQWio004e1YBtVqgWTP7Jg7mRKSgAAgNteuqiYiIiOgvqtpX3zpy5AgmT55slZAAgLe3NyZOnIjDhw/bvXFkzTyn5OYbKALyUKqQEIHTpxXIywP++EOBtm1NUNVogF7VzC9/YSEnuxMRERGRfVQ7KamKJPEgtb6p1XIvRUU3UASA2FgjCgokbNyohlIp0KmT/S4FbKZSycPImJQQERERkb1UOynp3Lkz3n//fRQUFFiVFxUV4YMPPkCXLl3s3Ta6ifk+JXp9xc83bSrQp08ZwsNN6N/fWG8T0b295eFbRERERET2UO3BPc888wzGjh2LhIQE9O3bFyEhIcjKysL333+P4uJifPrpp/XZTkJ5UlJaeuteinbtBNq1s+/k9pt5ewvodOwpISIiIiL7qNHNEz///HO899572LNnD/Ly8uDn54eePXviH//4ByIiIuqznQTrmyc6kre3QHq6AkIAHLVHRERERHVVaVJiMpmwa9cuhIWFQavVokOHDnj77bet6pw8eRJ//vknk5IGUN5T4th2eHrK90HR68vvW0JEREREVFuVzin56quvMH36dHh4eNyyjpeXF6ZPn47NmzfbvXFkzZyUyDdPdBzz/VIc3WNDRERERI1DlUnJiBEj0LJly1vWCQsLw8iRI7Fhwwa7N46sVXbzxIZkzlFLSjh2i4iIiIjqrtKk5Pjx44iLi6tyJX369MGxY8fs1iiqWGU3T2xI7u5yclRc7Nh2EBEREVHjUGlSUlhYCF9f3ypX4uvri8LCQrs1iipmvnmio3sozPNIHN0OIiIiImocKk1KAgICcOnSpSpXcvnyZQQEBNitUVQxcw+Fo+dyuLvLV90qKXFsO4iIiIiocag0KenWrRtSU1OrXMmGDRvQrVs3e7WJbsHcQ6HXO7aHQpLk+S3sKSEiIiIie6g0KXn88cfx448/Yv78+TBUMJGhtLQU8+bNw759+zBu3Lj6aiNdZ776ljPM5fDwcI52EBEREZHrq/Q+JbGxsZgxYwaSk5OxadMmxMXFoUWLFgCAP//8E2lpacjNzcWMGTPQpUuXhmjvX5okyUO4HN1TAsjtYE8JEREREdlDlXd0HzduHCIjI/HBBx9g+/btKLk+kcDd3R233347Jk2ahO7du9d7Q0nm7u74OSXmdmRlOboVRERERNQYVJmUAECPHj3Qo0cPmEwm6HQ6AIC/vz+USmW9No5subkJJ0lK2FNCRERERPZRraTETKFQICgoqL7aQtXg5gYUFzs+GXB3B0pLJZSVAaoavYuIiIiIiKxVOtGdnI88p8TRrQA8POTLE/OywERERERUV0xKXIw8p8Q5ekoA5+i1ISIiIiLXxqTExcjDtxzdihvv6u7YdhARERGR62NS4mKcZfiW+e7ynOxORERERHXlkKRk9erVSEhIQHR0NEaMGIGDBw9WWv/AgQMYMWIEoqOj0b9/f6SkpFg9n5CQgIiICJufSZMmWeosXrzY5vm4uLh62b/65ObmXMO32FNCRERERHXV4NdN2rp1K+bPn4/Zs2ejW7duWLNmDSZOnIgtW7agefPmNvXT09MxadIkjBw5Eq+99hoOHTqEOXPmIDAwEAMHDgQArFu3Dkaj0bJMZmYmRowYgfvuu89qXeHh4fj0008tj13xksbOcvNElQpQq4VTDCUjIiIiItfW4EnJihUrMHz4cIwePRoAMGvWLOzevRspKSmYPn26Tf3PPvsMoaGhmDVrFgCgbdu2OHLkCJYvX25JSgIDA62WWbduHby9vW2SEpVKhZCQkPrYrQbjLJcEBuTeEg7fIiIiIqK6atDhWwaDAcePH7cZNhUXF4fDhw9XuMwvv/xiUz8+Ph7Hjh1DaWmpTX0hBNatW4cHHngA7uYxRtelp6cjPj4eCQkJmDZtGtLT0+u4Rw3PWeaUAICXl0BRkaNbQURERESurkF7SnQ6HYxGI4KDg63Kg4KCkJaWVuEyWVlZ6N27t1VZcHAwysrKoNPpEBoaavXc3r17cfHiRUtPjFlMTAwWLFiANm3aICcnB0uWLEFiYiI2b96MgICAStutVErw9/es7m7WC6VSAX9/T/j5STAYHN8eAGjSBLh0SYK/v3B0U6rNHEeqG8bRPhhH+2Ac7YNxtA/G0T4YR/twpTg2untxr127FtHR0ejQoYNV+V133WX1uHPnzhgwYABSU1Mxfvz4StdpNArk5jq2S8Df3/N6G9xQXKx2eHsAQAgFsrKUyMkphcJFruNWHkeqC8bRPhhH+2Ac7YNxtA/G0T4YR/twxjiGhPhUWN6gh5IBAQFQKpXIysqyKs/Ozr7lXI/g4GBkZ2dblWVlZUGlUtn0cGRnZ2Pnzp02vSQV8fLyQrt27XD+/Pma7YSDubsLlJQAwgk6J7y85HZwCBcRERER1UWDJiUajQaRkZE2Q7XS0tIQGxtb4TJdunSpsH5UVBTUarVV+fr166FWqzF48OAq26LX63Hu3DmXm/ju5gYIIaGC6TQNzstLzowKCznZnYiIiIhqr8EH3YwfPx4bNmzAF198gbNnz2Lu3LnIyMhAYmIiACApKQlJSUmW+omJibh69SrmzZuHs2fP4osvvsCGDRswYcIEq/WaJ7gPHjwYXl5eNttNTk7GgQMHkJ6ejiNHjuCpp55CUVERhg8fXr87bGfmmxY6w2T38qTEwQ0hIiIiIpfW4HNKBg0aBJ1OhyVLliAjIwNarRbLli1DixYtAACXL1+2qt+yZUssW7YMCxYsQEpKCkJDQ/Hiiy9aLgdstn//fpw/fx6vvfZahdu9cuUKnnnmGeTm5iIgIABdunTB2rVrLdt1FW5u8u/iYgk+Po4dw+V5fd6U3FPiBOPJiIiIiMglSUI4w+wE51ZaanT4JCHzRKU1a1R4+mkPHDpUgJYtHf/SrVmjglZrQvfuJkc3pVqcccKXK2Ic7YNxtA/G0T4YR/tgHO2DcbQPZ4yjU0x0p7oz95Q4w/AtQG6PM9xhnoiIiIhcF5MSF2O+H6Sz3EldTkoc3QoiIiIicmVMSlyMeaJ7SYmDG3KdfIli50iQiIiIiMg1MSlxMeXDt5wjEWBPCRERERHVFZMSF+NMlwQGADc34TRtISIiIiLXxKTExdx4SWBn4O4OGAwSTK5x8S0iIiIickJMSlyMeaK7s/ROmJMkZ5njQkRERESuh0mJi3Fzc77hW4DztIeIiIiIXA+TEhfjbJcELu+5cY72EBEREZHrYVLiYpztksAaDXtKiIiIiKhumJS4GGe7JLBGI/8uLXVsO4iIiIjIdTEpcTEaDSBJwml6StRq+bfB4BxJEhERERG5HiYlLkaS5HkcztJTYk5K2FNCRERERLXFpMQFubk5z5wShQJQqQQMBke3hIiIiIhcFZMSF+Rsd1FXq4HSUufouSEiIiIi18OkxAW5uzvPJYEBeZ4Le0qIiIiIqLaYlLggd3fnmegOyD0lZWWObgURERERuSomJS7Izc15JroD8r1KePUtIiIiIqotJiUuyJkmugPmOSWObgURERERuSomJS7I3d25JrpzTgkRERER1QWTEhfkbBPd1WrBnhIiIiIiqjUmJS7I2S4JrNEAZWUSTCZHt4SIiIiIXBGTEhfkfD0l8u8DB5SObQgRERERuSQmJS7I2S4JHBgoAACnTvHtREREREQ1x6NIF+RslwRu0kSga1cjAN6vhIiIiIhqjkmJC5KTEke3wpqbm/zbmXpwiIiIiMg1MClxQebhW0I4uiXl3NzkxjhTDw4RERERuQYmJS7I3R0QQnKqe4OYe0qcqU1ERERE5BqYlLig8l4JBzfkBuY2cfgWEREREdWUQ5KS1atXIyEhAdHR0RgxYgQOHjxYaf0DBw5gxIgRiI6ORv/+/ZGSkmL1/OLFixEREWH1ExcXZ1VHCIHFixcjPj4eMTExGDt2LE6fPm33fWsI5fM3nGeolEYj/zYYnKdNREREROQaGjwp2bp1K+bPn48pU6YgNTUVsbGxmDhxIi5dulRh/fT0dEyaNAmxsbFITU3F5MmTMXfuXGzbts2qXnh4OPbs2WP52bRpk9XzH3zwAZYvX45Zs2Zh3bp1CAwMxPjx41FQUFBv+1pfPDycr6fE3V3+7UxtIiIiIiLX0OBJyYoVKzB8+HCMHj0abdu2xaxZsxASEmLT+2H22WefITQ0FLNmzULbtm0xevRoDBs2DMuXL7eqp1KpEBISYvkJDAy0PCeEwMqVKzFp0iQMHDgQWq0WycnJKCwsxObNm+t1f+uDM/aUKBSAWu1cd5onIiIiItfQoEmJwWDA8ePHbYZWxcXF4fDhwxUu88svv9jUj4+Px7Fjx1BaWmopS09PR3x8PBISEjBt2jSkp6dbnrt48SIyMzOt1uPu7o4ePXrccrvOzFkvv6vR8OpbRERERFRzqobcmE6ng9FoRHBwsFV5UFAQ0tLSKlwmKysLvXv3tioLDg5GWVkZdDodQkNDERMTgwULFqBNmzbIycnBkiVLkJiYiM2bNyMgIACZmZmW5W7ebkZGRpXtViol+Pt71mRX7U6pVFjaYN4NjcYd/v6Oa9PNAgMBtRpO1aab3RhHqj3G0T4YR/tgHO2DcbQPxtE+GEf7cKU4NmhSUl/uuusuq8edO3fGgAEDkJqaivHjx9d5/UajQG5uUZ3XUxf+/p6WNpSVKQF4IjNTj9xco0PbdSMhlLh6VUJurvPe1v3GOFLtMY72wTjaB+NoH4yjfTCO9sE42oczxjEkxKfC8gYdvhUQEAClUomsrCyr8uzsbISEhFS4THBwMLKzs63KsrKyoFKpEBAQUOEyXl5eaNeuHc6fPw8AlnVXtN2be09cgTNeEhgAAgIE8vIkGJ0nTyIiIiIiF9CgSYlGo0FkZKTNUK20tDTExsZWuEyXLl0qrB8VFQW1Wl3hMnq9HufOnbMkI2FhYQgJCbFaj16vx8GDB2+5XWfmjBPdATkpEQLIzXWudhERERGRc2vwq2+NHz8eGzZswBdffIGzZ89i7ty5yMjIQGJiIgAgKSkJSUlJlvqJiYm4evUq5s2bh7Nnz+KLL77Ahg0bMGHCBEud5ORkHDhwAOnp6Thy5AieeuopFBUVYfjw4QAASZLw2GOP4YMPPsA333yDU6dOYebMmfD09MT999/fsAGwA2e8JDAgJyUAoNM5uCFERERE5FIafE7JoEGDoNPpsGTJEmRkZECr1WLZsmVo0aIFAODy5ctW9Vu2bIlly5ZhwYIFSElJQWhoKF588UUMHDjQUufKlSt45plnkJubi4CAAHTp0gVr1661rBMAJk6cCL1ej1deeQV5eXno3Lkzli9fDm9v74bZcTty1qtv+foCKpW43lMiHN0cIiIiInIRkhCCR49VKC01OnyS0I0TlTIyJERFeePVV0swYUJpFUs2rA0bVAgOFrjjDuecWOKME75cEeNoH4yjfTCO9sE42gfjaB+Mo304YxydYqI72Ye7u3MO3wLkO7s7Ww8OERERETk3JiUuyN1d/u2MNyp0dxdONwGfiIiIiJwbkxIXpFYDkiScskfCwwMoLnZ0K4iIiIjIlTApcUGSZB4m5Xw9Eu7uAnq9BM5UIiIiIqLqYlLiotzdnXNOiZsbIIRzto2IiIiInBOTEhfl5uacw7fMk/CdsW1ERERE5JyYlLgoNzfnHL7l4SH/dsa2EREREZFzYlLiouS5G45uhS1zT8k336hQUODgxhARERGRS2BS4qLkOSXO1xvh7V3+d36+87WPiIiIiJwPkxIX5axzSlQq4IEH5LvMGwwObgwRERERuQQmJS7KWeeUAIBGI/92xp4cIiIiInI+TEpclLNeEhgoT0rYU0JERERE1cGkxEW5uzvn8C1AHsKlVDpv0kREREREzoVJiYvy9ASKipx3eJRGI2AwOG/7iIiIiMh5MClxUd7eAgUFznvQ7+bGnhIiIiIiqh4mJS7Ky0ugoAAQwtEtqZjcU+LoVhARERGRK2BS4qK8vYGyMslpeyM0GnD4FhERERFVC5MSF+XtLXeROOsQLg7fIiIiIqLqYlLiosxJSWGhgxtyCxy+RURERETVxaTERXl5yb+duaekrExCWZmjW0JEREREzo5JiYvy8nLu4Vu+vnL7cnOds31ERERE5DyYlLgoZx++FRwsty87m0kJEREREVWOSYmL8vaWfztrT4m3tzyvJCfHOdtHRERERM6DSYmLKr/6loMbUomgIMGeEiIiIiKqEpMSF2We6F5Y6LwH/UFBArm5EoxGR7eEiIiIiJwZkxIX5ez3KQGAwEABk4mT3YmIiIiockxKXJSbG6BWC6cfvgVwsjsRERERVY5JiQvz9nbunhIfH052JyIiIqKqMSlxYd7ewqmTEgAICRG4etW520hEREREjuWQpGT16tVISEhAdHQ0RowYgYMHD1Za/8CBAxgxYgSio6PRv39/pKSkWD2/dOlSjBw5El27dkWvXr0wZcoUnDp1yqrOzJkzERERYfUzevRou+9bQ/L2Frh2zdGtqFyTJgJ5eRKKihzdEiIiIiJyVg2elGzduhXz58/HlClTkJqaitjYWEycOBGXLl2qsH56ejomTZqE2NhYpKamYvLkyZg7dy62bdtmqXPgwAE8/PDD+Oyzz/DJJ59AqVRi/PjxyM3NtVpXnz59sGfPHsvPsmXL6nNX611AgHD6SeTNmsnzSq5cce52EhEREZHjqBp6gytWrMDw4cMtvRSzZs3C7t27kZKSgunTp9vU/+yzzxAaGopZs2YBANq2bYsjR45g+fLlGDhwIADgo48+slpm4cKF6N69O37++WckJCRYyjUaDUJCQupr1xqcv7/AuXPOPQIvMFBAqQRyciS0aSMc3RwiIiIickINekRrMBhw/PhxxMXFWZXHxcXh8OHDFS7zyy+/2NSPj4/HsWPHUFpaWuEyhYWFMJlM8PX1tSo/dOgQevfujYEDB+Kll15CdnZ2HfbG8QICBHQ65+6BkCTA01OgqMi520lEREREjtOgPSU6nQ5GoxHBwcFW5UFBQUhLS6twmaysLPTu3duqLDg4GGVlZdDpdAgNDbVZZt68eejYsSNiY2MtZXfccQfuvvtuhIWF4c8//8SiRYvw+OOPY/369dBoNJW2W6mU4O/vWd3drBdKpcKmDU2aSMjNdXzbqhIaChiNgL+/o1tScRyp5hhH+2Ac7YNxtA/G0T4YR/tgHO3DleLY4MO36tuCBQtw6NAhpKSkQKlUWsoHDx5s+TsiIgKRkZFISEjArl27cM8991S6TqNRIDfXsTO1/f09bdrg4aFBSYkbLl8ugoeHgxpWLUpkZEjIzS1zdEMqjCPVHONoH4yjfTCO9sE42gfjaB+Mo304YxxDQnwqLG/Q4VsBAQFQKpXIysqyKs/Ozr7lXI/g4GCbYVZZWVlQqVQICAiwKp8/fz62bNmCTz75BC1btqy0LU2aNEGTJk1w/vz5mu+Ik/D3l+do5OU599AoLy+B4mIJJpOjW0JEREREzqhBkxKNRoPIyEiboVppaWlWQ61u1KVLlwrrR0VFQa1WW8rmzp1rSUjatm1bZVtycnKQkZFR4fAvVxEQICclzj6vxMsLEAK8LDARERERVajBL900fvx4bNiwAV988QXOnj2LuXPnIiMjA4mJiQCApKQkJCUlWeonJibi6tWrmDdvHs6ePYsvvvgCGzZswIQJEyx15syZg/Xr1+P111+Hr68vMjMzkZmZicLCQgDyxPfk5GQcPnwYFy9exP79+/H3v/8dgYGBGDBgQMMGwI7MPSXOfllgT0+5nYWFzt1OIiIiInKMBp9TMmjQIOh0OixZsgQZGRnQarVYtmwZWrRoAQC4fPmyVf2WLVti2bJlWLBgAVJSUhAaGooXX3zRcjlgAFizZg0AYNy4cVbLTp06Ff/85z+hVCpx6tQppKam4tq1awgJCUHPnj2xaNEieHt71+8O1yNX6Snx9S1Pnpo04WWBiYiIiMiaJITgUWIVSkuNDp8kVNFEpfR0Cd26eWPRomI8/LDjJ5FX5ssvVQgMFOjXz+jQdjjjhC9XxDjaB+NoH4yjfTCO9sE42gfjaB/OGEenmOhO9uUqPSUA0Ly5wNWrnOxORERERLaYlLgwLy/Aw0MgI8P5X8YmTUwwGCTk5jq6JURERETkbJz/aJZuSZKAZs0ELl1y/p4Sc6+Os0/KJyIiIqKGx6TExbVoYcKffzr/y+jrKydR+flMSoiIiIjImvMfzVKlWrQQ+PNP5z/QVyoBHx/BnhIiIiIissGkxMU1b27C1asSypz74lsAAD8/4fR3nyciIiKihsekxMW1aCFgMkm4csX5D/b9/QWuXeMVuIiIiIjIGpMSF9eihXyE7wrzSvz8BEwmID/f0S0hIiIiImfi/EeyVKnbbpOTknPnnL+nxM9P/s15JURERER0IyYlLi48XMDdXeDECaWjm1IlPz/5ssC8AhcRERER3YhJiYtTKgGt1oRff3X+l1KlAry9eQUuIiIiIrLm/EeyVKWOHU04ccI1Xkp/f4HsbCYlRERERFTONY5kqVKdOhmRkaFAZqbzH+w3bSpfgaugwNEtISIiIiJnwaSkEejWzQgA2LfP+eeVNGsmT8y/etX5EygiIiIiahhMShqB2FgTvLwE9uxx/qTE3x/w8BD45Rclrl1zdGuIiIiIyBkwKWkE1Gqgd28jdu92/qREkoCEBCNKSiT89hvffkRERETEpKTRSEgow5kzSpw65fwvaVCQQLNmJqSnO39biYiIiKj+8aiwkRgypAySJJCaqnJ0U6qlZUuBggIJX3+tgsnk6NYQERERkSMxKWkkmjQRiI83YtUqNQoLHd2aqoWHmxAWZkJmpuQSVw0jIiIiovrDpKQRmTFDjytXFHjnHY2jm1IllQqIjzdCoQD+/JNJCREREdFfGZOSRuT2200YNqwU772ncYkDfY0GCA014dgxJU6f5luRiIiI6K+KR4KNzKxZekgS8NRT7jAaHd2aqnXvbkRQkMD+/Urk5Tm6NURERETkCExKGpmWLQXmzdNj924Vnn7aHXq9o1tUucBA+cphKpXA7t0ql0ikiIiIiMi+mJQ0Qo88UoqkJD0+/1yN++/3REaGcw/l8vAA+vQxIidHwt69ShgMjm4RERERETUkJiWN1LPPGvDJJ8U4dUqBvn09sWSJGsXFjm7Vrd12m0DXrkacP6/AV1+pmJgQERER/YUwKWnE7ruvDFu2FEGrNWH2bHfcfbcnUlJUyMkBhHB062xFRZlw991lKCqSsG+f0umHntXE1asSNm1iskVERERUESYljVxUlAmpqcX47LMiCAH8618e6NDBByNGeGDVKjV+/VXhVPcJadZMICpK7jFZu1aNbduUuHDBedpXWxcvStDpeE8WIiIiooq4xu2/qc4SEozo168I+/YpkZamxPvva7B3b/nL37GjEXfeaUS7dvJNDaOiTGjSRO5OEQKQGvBYumtXE/z9BfbsUeHqVQWuXlWgZ08j2rc3QeGiabROJwcwK0tCkyYCSmXDxpSIiMiZFBcD332nQmCgQPfuRqh4RPqXx7fAX4gkAb17G9G7txH/+pcB589LOHpUiYsXFfj+eyU+/lgNvV4+UlarBSIjTbh4UUJRkYQ+fYzw8xPo378MYWECKpVAixYCzZqVjwMrKZFvimiPD5Y2bQRUqjIEBgqkpSmxf78Sv/6qQPPmAu3bG+HrCyiVgF4PlJXJ+3bkiBIXL0oIDha4/XYjPD3hNEmMOSk5ckSJ48cVaNpUoG9fo9O0j4jIGVy9KkGjEQgIcHRLqL7t3q1EVpaErCwJubnAHXcY4eXl6FaRI0lCOOPsAudSWmpEbm6RQ9vg7+9Z720wGuUvhAsXFNi8WYXTpxVo1syEkhIJv/6qQE6OhIwM66PowEAT1GrAZAIyMxUIDTWhVy85gQHkGySGh5vg5ycQFCSQkyMhIEDg9GkFOnY0ITrahKAgAYNBrltR74HJBFy4IOHXX5XIzQXKyuRKnp4CJSUSTKbyuq1amXD5sgSDQYJCATRvboKnp3xGxstLQKt1h9FYDA8PAXd3ed31fXamqAhYt04NhULenpeXQGGhhJAQgaZNTSgrA5o0EQgLEy6TpDTE+/GvgHGsG3Mv7q3iWFQEbN6sQq9eRtx2G7/qquLo96MQwKefqgEAjz1W6rB21JWj4+gKMjIk/Pe/KvToYYSHh3zyEQCaNhVo396Eli0F41iB0lL5/0Sjqf4yzhjHkBCfCssd1lOyevVqfPTRR8jMzET79u3xwgsvoHv37resf+DAAbz66qs4ffo0QkND8cQTT2DMmDE1WqfBYEBycjI2b94MvV6PXr164eWXX0bTpk3rbT9diVIJNG8u0Ly5Eb162d4wxGQCjhxRID9fQlkZcPy4En/+KaH0+ndHs2YCR4/KPRq5uXKyUFwsobi48nFKbm4Cer2E0FAT3NwAtVru/fDwEAgNFfDyElCr5XJJAq5dAwoLAUmS4OEh4O0tkJ8v4Y8/5B6IVq1MljYZDEoUFsqXHXZ3B/z8JKhUauj18j92fr4C4eEmuLsLCAEUFkrw9pYTFn9/AS8vQKkUuHRJQlmZhNtuM6GoSMK1a0B4uJxMKRRyYuPmBmRkABkZCrRvb7ye9EjIyZFw8KACJ08qcPvtRowebYQQcqyuXFFCowF+/RUwGIDQUAFfX3mfzWeMrl2TE7krVyR4esoJTVCQ3N6yMjku5mRGrwe8veXYeXnJSY5GAxQVSXB3l+NcUiLXCwkRMJnk1720VP6dlSVvy8dHPqDTaOQ4GY1ynbIyCUaj3Fbz9pVKWOJwY++UwSAvIydisCSegPw6FhbKr4l5O+7utu+NsjL59TYYJEiSvC2lUqCgQEJYWPlBZlaWvF/mMoNB3kcfn/L1qFTlB7F5eYBeL7/WRqMcs4wMOVFUKOT6V65IUKnkdanVQGCgwLlzCrRsKb9Py8rktufmSjh/XgGFArjtNhMMBgl+fgKSJCfOgBwTDw85jhV9mRQUyM8rlZX+q9SboiJUO0k3GmvXTqNRjsOthi2WlMhtKC6WXzuNRm7Lrb58c3OBb75RISrKhLAw+fUMDhZW6z97VmE5qXLbbVXfBKmhh6pWl8Egx8L8v+Ws7ayOvDy57b6+ts9lZUlW9Xx8yvfd2Yb2nDypQGCgQEgIk93a+PVXBTQaOQFRqYCgoDLLMcV336kQECDQuzcghO3/tT1cuSKvsGlT5339Kvqs3bVLiZISCUOGlDmmUfXMIT0lW7duxXPPPYfZs2ejW7duWLNmDdavX48tW7agefPmNvXT09MxZMgQjBw5Eg8//DAOHTqEOXPm4M0338TAgQOrvc7Zs2djx44dSE5Ohr+/P1599VXk5+dj/fr1UFbyLftX6SmpD4WFQEmJ3DWbnS1/uFy+rEDTpiacPavA+fMKXL6sgJubwB9/KCCEfFCi0chfRhkZCpSUyAe3paXyAbEQgLe3fHBuMJQfEMfGmqDTyQcgJSXyF5/RKEGplA++hbD/t7hSKa4flEtQqYSlFwcAJElYPlDMCc3FixJMJus6Hh5y0gDIw+b8/AR8fASKiiQUF8uJk0olrh+kyb/NSZpGIywHzkLIB8EVvZXVaqCgoDyZkeMh/775b6VSru/mVv6hqFIJlJZKUKvlBLGkRAk3NyPUavP+mX8keHnJbVep5OROp5MP0hUKeV1Go5yk3LxtNzf5dZITIMmyH0pleT0AcHcXMBolyzKlpXKSaDQCvr4Cbm7y62FOmDw85BiZb8xZXCxZEp3AQDnWbm5Afr5cXwh5+/LrU/4aFxXJSYw5uTEnatnZ8v4VF0twc8P1JFpY9kGlEpb1mvdDpZLfl0FBKly9WobCQnkdclIn0KSJQEaGnBT5+8vJ5KVLkiVJ9vKSv6Q1Gnlf8vLk19Zkkg/sPDzkbRUVAQEBwpLwlZTIdX195cSzuFiOhznxAgAfH2H5H1Or5cdlZRKysyUUFMhf5iUlEkJDBZo0MVneLwAscTaZ5DKDQU6qlUogP1+Cm5v8/tVoBHQ6BXx8hOX1ycmR45uXJ7+25gTG11d+zc2Pi4qAq1cVKCwsT8p9fdUoKSmFRgOEhJig10u4elVur9Eor1erNcHLS46lySSfADAa5TaXlsrty8uT4OMjl5eVlf8/mRN3b28gKEhYklp3dzmhlHtB5RM08usoLO91Nzf5f6CsDJaTBAqF/H9vPmHi4VH+/tZo5BgVF8tJWmamhJ9/VkKhAJo0MSEnR/58M58MCQ42wcNDPiEgSfL7z/we9vISljYUFMixzMuT3wMBAQIajfy8TqdAWRkQGuqG0tISBAXJib/JBMtrIsdZWE4ayScp5DYUFkr46SclhADCwuT3xPnzChgM8vsnIEA+yZKTIyE3V4JGI/dqt2xpQmmpdP0EkYT8fGD/fiXc3eX3rTkRMRrl9TRvLiz/0+Yk381N7jE3n7AoLJRQUCABEJbPAflzQ37e21t+DQoK5KRHqRTXT5JIVp8T+fny/2RBgXzyS34vCmRmyifACgvlEyXm17t9e/l1kMs8kJ9fjKIi+WSHv3/5GW4vL2GpZ/6MMZnkRFw+4SMPX/P1Lf/+VCjkzxcfH/n/oLBQPtnl7i7vr8kkx8fdXf5fkaTy/x/z/pi/C729yz+L8vPlRgQGChQWlsdAp5PX7e8vLCMRcnPlzw2TSf4/LiiQUFgov898fOT3bG6uZHn/5eVJltfJ01N+LfX68u+AtDQVoqONiI29YajD9e+So0cVuHBBgbIyNxQVGeDlJY+0UCrlzzAfH/n9AcBy0rL0po41SZJ/hLA+GSJJwG+/KXDunOL6cYMRTZvK+2k+8WU0yp9zSqX8Gri5wfIdptGUf0/IJzLl71bz+tVq+TNfpZLfc+bvRm9vOeYlJfK6AwMFhJDfn2fPKlBQIG+/rEyOvUYjvw7+/gKtW5ss6zp4UP5i7N7dCG/v8s8n8/tfoSjf32vX5NejaVNPXL1ahLIyuU2enrbHCA3tVj0lDklKRo0ahYiICMydO9dSds8992DgwIGYPn26Tf3XXnsN3377Lb755htL2YsvvogzZ87g888/r9Y6r127ht69e2P+/Pl44IEHAACXL19Gv3798MEHH+COO+64ZXuZlLiuvLzyM66ZmRIMBg/88Yf++pe1hObNTfjjD/kDwfyPLYR8AGr+kDYYcD1RAC5flj+AJQm4dEmBoiL54MTLS/7SCAoSCAuT12lOpoxGCTExRgwdWobcXAnffqtEdrZk+SK8dk0+aPLwkL+0r1yRD6i8vOQvpubNTSgulg96CgvlL62CAvnLSu71kCxfRHl5kiVBMX+ZGI3y/vj5CWRmygmO+Yyr+eyrUikfKJl7VUpL5Q9ajUY+IDUY5A9mvV7+EvL3lw/Mbkz01Grzl4b8ZWQwyPvu7i4fNNQ3SRI1SDzNX2QuerqZqFLlSZz5p6ysdidmFAp5XeYTFOaeUet1CQA1X7dKJR9+lJVJt/j/NSd3crn5BIH5YNPMnAhXZ/8UCvmg2fx5Jp8kkNug0QjLus0nSG61ToWi/AQFUB5nc9zNJy5MJlxPjCTLPqtU1gfNQPlBbkWPb/wxf2bL6xBWB9w3Ln8j8/Pmz/0bex3MJ4dujHFxsWTTsynHSE4wboyRySRZEp8bY6BQCEuZEPL3gtzjJSeL5nUqlXKCodfLr4l5O+ae+bIyYbXuG19vcxzKT/bI34FyD6u8naIiObGWl5Nf4+JiORnw9RXX91k+gNdo5HiWn5Qy95zLJ9nMIznMr6m5HfL3J66fEJPLzSeCbvU6muNUWiqv09yrbh6BYDRKludN1nmb1SgJc0+yebSDeXSD+bWV/5bjaH5NP/ywBHFxVfcc1yenGb5lMBhw/PhxTJgwwao8Li4Ohw8frnCZX375BXFxcVZl8fHxSE1NRWlpKYQQVa7z2LFjKC0tRXx8vOX5Zs2aoW3btjh8+HClSQm5Lj+/8r+bNxfw9wdat7b+Z2zZsuH+OYODBcaMcd1uVyHkL/KmTT2Rk1NkOTt14xAy8zAtObnD9Z6g8rN2anX5Gbobh2SZE0JJkj/Q5d4x+QtBoRCWHhP5jLv8pSOfjZPP9MlnbOUvF/kLQli2lZUlJ36lpfIZKn9/eX1Xr8qXalYq5fpubuX7af7SNffS+fgIZGWVn8U39xC0bGmyDPvLzZXXV1go9waVlpYncvIXqLAcVOj1gKenO1SqEstwtoKC8rP7anX52VKTSd7HsjJ53ebYmX/f+IV942NPT/mLOSenfKijEHKM9Hrpei9I+ZeseXieuRfI3DMpn4GVY+TjIw+r1Onk3hPzAcmNB1Pl7xe5UeYvVfOBnjxcUr5EdlGRHEe5V6n8QNV8oGRug/kL1t0daNtWnotl7lGQJDcUF+shhNymgACBFi1MluFyGRlyom9OsM29OOUHF9L1g4TyM403H+wB5XExHwwBcs+JPJRPsupBk/+WE3wvL2E5eDDHwDxczfz+AMwHr/Ly5oNmLy/5c8vP78bXSrIcFJl7dcyvnfmA7sbeT/NQRXP81GrzcDp5f93dzQeIGmRllaKwsHy4rPmEiHwwJx9cmk+iKBTyfqjVQOvW8tURCwrk/6emTQWys+WePDO5x0ayHLjl5UmWkyHmntHOnU3IzweysuSTPnIvidw7kpEhzxc076e5l+HGnjQ3N/lH/h+V/+fNZ+jl9snLGgzlJ3MMBvnssfmMtyTJJ1nkng05lnJvqflMs7AMUZbfF/L72Pz6qFQqGAxlcHMr73l0c5PXU1Agn4wyvz7mg1PzZ6h57qHciycs5eYDXvkgVboh0SxPgG5cp+3/ovm9Ilkem//f5OHSchuKigB/f1w/mXRje+TlzL3S8mdweS+puUfC3DNgXs78OeLtXd5+T8/y/TUa5d5m+USWZOl9U6sFPD3lOJrf8+bPXqC8N7C4uHyORUmJPD/TfCLO3V0eDm0+CWju1fPzEwgMlD/P9Xr5PRoSIr+/y8pwvce7fMipSiW/bgUF8usst8/8IyfkZWXyut3dxfWe4fLvN4XCOhHx8LBOXuSkDVafPebk+8YE1/z54OYmJ0x6vdwe8/6bP4cAWL5vzO9HpdIIjUb+PGnX7qYsx4k0eFKi0+lgNBoRHBxsVR4UFIS0tLQKl8nKykLv3r2tyoKDg1FWVgadTgchRJXrzMrKglKpRMBNl/QICgpCVlZWpW1WKiX4+zu2v0upVDi8DY0B42gfSqUCgYFVx9H87xYYaF3erFk9NOqG7d2oRYua1a+LJk1qVl+pVMBorGAyDdWIHEc3RzfD5SmVEoxGJ5u84YLkODpoglgj4ppxdKbed3PvF2A03ngVHQ/HNKca+OlTDUajcPjQKQ7fsg/G0T4YR/tgHO2DcbQPxtE+GEf7YBztwxnjeKvhWw1+AdKAgAAolUqb3ons7GyEhIRUuExwcDCys7OtyrKysqBSqRAQEFCtdQYHB8NoNEKn09nUubmHhYiIiIiIGk6DJyUajQaRkZE2Q7XS0tIQGxtb4TJdunSpsH5UVBTUanW11mmuu3fvXsvzV65cwdmzZ2+5XSIiIiIiqn8OGb41fvx4JCUlISYmBl27dkVKSgoyMjKQmJgIAEhKSgIALFy4EACQmJiI1atXY968eUhMTMTPP/+MDRs24I033qj2On18fDBy5Ei89tprCAoKgr+/PxYsWICIiAj06dOngSNARERERERmDklKBg0aBJ1OhyVLliAjIwNarRbLli1Di+szUi9fvmxVv2XLlli2bBkWLFiAlJQUhIaG4sUXX7Tco6Q66wTkywirVCpMmzYNJSUl6N27NxYuXFjpPUqIiIiIiKh+OeQ+Ja6G9ylpPBhH+2Ac7YNxtA/G0T4YR/tgHO2DcbQPZ4yj00x0JyIiIiIiuhGTEiIiIiIicigmJURERERE5FBMSoiIiIiIyKGYlBARERERkUMxKSEiIiIiIodiUkJERERERA7F+5QQEREREZFDsaeEiIiIiIgcikkJERERERE5FJMSIiIiIiJyKCYlRERERETkUExKiIiIiIjIoZiUEBERERGRQzEpISIiIiIih2JS4gJWr16NhIQEREdHY8SIETh48KCjm+RUfvrpJ0yZMgV33HEHIiIisH79eqvnhRBYvHgx4uPjERMTg7Fjx+L06dNWdfLy8vDcc8+hW7du6NatG5577jnk5+c35G441NKlSzFy5Eh07doVvXr1wpQpU3Dq1CmrOoxj1VavXo0hQ4aga9eu6Nq1Kx566CHs2rXL8jxjWDtLly5FREQEXnnlFUsZY1m1xYsXIyIiwuonLi7O8jxjWH0ZGRmYMWMGevXqhejoaAwaNAgHDhywPM9YVi0hIcHm/RgREYFJkyZZ6lR1vGMwGPCf//wHPXv2RJcuXTBlyhRcuXKloXfFoYxGIxYtWmSJU0JCAt566y2UlZVZ6rjs+1GQU9uyZYvo1KmT+Pzzz8WZM2fEK6+8Irp06SL+/PNPRzfNaezatUu88cYb4uuvvxYxMTHiyy+/tHp+6dKlokuXLuK///2vOHnypHjqqadEXFycuHbtmqXO3/72NzFo0CDx888/i59//lkMGjRITJ48uaF3xWEmTJgg1q1bJ06ePCl+++038Y9//EP06dNH6HQ6Sx3GsWrffvut2LVrlzh//rz4/fffxZtvvik6deokTpw4IYRgDGvj8OHDol+/fmLIkCFizpw5lnLGsmpvv/22GDhwoMjIyLD8ZGdnW55nDKsnLy9PJCQkiOeee04cOXJEXLhwQaSlpYkzZ85Y6jCWVcvOzrZ6Lx4/flxERESI9evXCyGqd7zz73//W8TFxYk9e/aIY8eOiUcffVQ88MADoqyszFG71eCWLFkievToIXbs2CHS09PF9u3bRffu3cU777xjqeOq70cmJU7uwQcfFC+++KJV2d133y1ef/11B7XIuXXp0sUqKTGZTCIuLk689957lrLi4mLRpUsXkZKSIoQQ4syZM0Kr1YqDBw9a6vz0009Cq9WKs2fPNlzjnUhBQYHo0KGD2LFjhxCCcayLHj16iJSUFMawFvLz80X//v3Fjz/+KB599FFLUsJYVs/bb78tBg8eXOFzjGH1vfHGG+Khhx665fOMZe289957olu3bqK4uFgIUfXxTn5+voiMjBQbN260PH/p0iUREREhfvjhh4ZruINNmjRJJCUlWZUlJSWJSZMmCSFc+/3I4VtOzGAw4Pjx41bd7QAQFxeHw4cPO6hVruXixYvIzMy0iqG7uzt69OhhieHhw4fh6emJrl27Wup069YNnp6ef9k4FxYWwmQywdfXFwDjWBtGoxFbtmxBUVERYmNjGcNamDVrFgYOHIhevXpZlTOW1Zeeno74+HgkJCRg2rRpSE9PB8AY1sT27dvRuXNnPP300+jduzeGDh2KVatWQQgBgLGsDSEE1q1bhwceeADu7u7VOt45duwYSktLER8fb3m+WbNmaNu27V8qht26dcP+/ftx9uxZAMCZM2ewb98+3HnnnQBc+/2octiWqUo6nQ5GoxHBwcFW5UFBQUhLS3NQq1xLZmYmAFQYw4yMDABAVlYWAgMDIUmS5XlJkhAYGIisrKyGa6wTmTdvHjp27IjY2FgAjGNNnDx5EomJidDr9fD09MQ777yDiIgI/PzzzwAYw+pau3YtLly4gNdee83mOb4fqycmJgYLFixAmzZtkJOTgyVLliAxMRGbN29mDGsgPT0da9aswbhx4zBp0iScOHECc+fOBQA8+uijjGUt7N27FxcvXsTo0aMBVO94JysrC0qlEgEBATZ1/koxnDhxIgoLCzF48GAolUqUlZVhypQpeOSRRwC49ucjkxIisrJgwQIcOnQIKSkpUCqVjm6OywkPD0dqaiquXbuGbdu2YcaMGfj0008d3SyX8vvvv+PNN9/EmjVroFarHd0cl3XXXXdZPe7cuTMGDBiA1NRUdO7c2UGtcj1CCERFRWH69OkAgE6dOuGPP/7A6tWr8eijjzq4da5p7dq1iI6ORocOHRzdFJezdetWpKam4o033kC7du1w4sQJzJ8/H2FhYRg1apSjm1cnHL7lxAICAqBUKm2y1uzsbISEhDioVa7FHKeKYmg+ixAcHIycnBxLVzwgfwnl5OTYnGlo7ObPn48tW7bgk08+QcuWLS3ljGP1aTQatGrVynIQ07FjR3z88ceMYQ388ssv0Ol0uP/++9GpUyd06tQJBw4cwJo1a9CpUyf4+/sDYCxrysvLC+3atcP58+f5fqyBkJAQtG3b1qqsTZs2uHz5suV5gLGsruzsbOzcudPSSwJU73gnODgYRqMROp3Ops5fKYYLFy7EhAkTMHjwYERERGDYsGEYN24cli1bBsC1349MSpyYRqNBZGSkzVCttLQ0y7AaqlxYWBhCQkKsYqjX63Hw4EFLDGNjY1FUVGQ1jvLw4cOWuQB/FXPnzrUkJDd/ATOOtWcymWAwGBjDGhgwYAA2bdqE1NRUy09UVBQGDx6M1NRUhIeHM5a1oNfrce7cOYSEhPD9WANdu3bFuXPnrMrOnz+P5s2bA+DnY02tX78earUagwcPtpRV53gnKioKarUae/futTx/5coVnD179i8Vw5KSEptRDEqlEiaTCYBrvx85fMvJjR8/HklJSYiJiUHXrl2RkpKCjIwMJCYmOrppTqOwsBAXLlwAIB8AXrp0CSdOnICfnx+aN2+Oxx57DEuXLkWbNm3QunVrLFmyBJ6enrj//vsBAG3btsUdd9yB2bNnW+6DMHv2bPTr1w9t2rRx2H41pDlz5mDjxo1499134evraxmT6unpCS8vL0iSxDhWw+uvv46+ffuiadOmKCwsxObNm3HgwAEsXbqUMawBX19fy0UWzDw9PeHn5wetVgsAjGU1JCcno1+/fmjWrBlycnLw3nvvoaioCMOHD+f7sQYef/xxjBkzBkuWLMGgQYPw66+/4tNPP8UzzzwDAIxlDZgnuA8ePBheXl5Wz1V1vOPj44ORI0fitddeQ1BQEPz9/bFgwQJERESgT58+jtgdh+jXrx+WLVuGsLAwy/CtFStWYNiwYQBc/P3Y0Jf7oppbtWqV6Nevn4iMjBTDhw8XBw4ccHSTnMq+ffuEVqu1+ZkxY4YQQr483ttvvy3i4uJEVFSUeOSRR8TJkyet1pGbmyumT58uYmNjRWxsrJg+fbrIy8tzxO44REXx02q14u2337bUYRyrNmPGDNG3b18RGRkpevXqJR5//HGrS1UyhrV34yWBhWAsq+Ppp58WcXFxIjIyUsTHx4upU6eK06dPW55nDKvvu+++E0OGDBFRUVHinnvuEZ988okwmUyW5xnL6vnxxx+FVqsVR44cqfD5qo539Hq9eOWVV8Ttt98uYmJixOTJk8WlS5caoulO49q1a2Lu3Lmib9++Ijo6WiQkJIg33nhDlJSUWOq46vtREuKGAWVEREREREQNjHNKiIiIiIjIoZiUEBERERGRQzEpISIiIiIih2JSQkREREREDsWkhIiIiIiIHIpJCRERERERORRvnkhERA1m/fr1eP755yt8zsfHBwcPHmzgFslmzpyJtLQ0/PDDDw7ZPhHRXx2TEiIianD/93//h6ZNm1qVKZVKB7WGiIgcjUkJERE1uI4dO6JVq1aObgYRETkJzikhIiKnsn79ekREROCnn37CP/7xD8TGxqJnz56YM2cOSkpKrOpmZGQgKSkJPXv2RFRUFIYMGYKNGzfarDM9PR3PPfcc4uLiEBUVhf79+2Pu3Lk29X799Vc8/PDD6Ny5M+655x6kpKTU234SEVE59pQQEVGDMxqNKCsrsypTKBRQKMrPlT333HO477778PDDD+Po0aN47733UFxcjFdffRUAUFRUhLFjxyIvLw/PPPMMmjZtiq+++gpJSUkoKSnBQw89BEBOSEaNGgUPDw889dRTaNWqFS5fvow9e/ZYbb+goADTp0/H448/jieffBLr16/Hyy+/jPDwcPTq1aueI0JE9NfGpISIiBrcfffdZ1PWt29fLF261PL4zjvvxIwZMwAA8fHxkCQJb7/9NiZPnozw8HCsX78e58+fx8qVK9GzZ08AwF133YXs7GwsWrQIDz74IJRKJRYvXgy9Xo+NGzeiSZMmlvUPHz7cavuFhYWYPXu2JQHp0aMH9uzZgy1btjApISKqZ0xKiIiowb377rtWCQIA+Pr6Wj2+OXEZPHgwFi1ahKNHjyI8PBw//fQTmjRpYklIzB544AE8//zzOHPmDCIiIrB371707dvXZns38/DwsEo+NBoNWrdujUuXLtVmF4mIqAaYlBARUYNr3759lRPdg4ODrR4HBQUBAK5evQoAyMvLQ0hIyC2Xy8vLAwDk5ubaXOmrIjcnRYCcmBgMhiqXJSKiuuFEdyIickpZWVlWj7OzswHA0uPh5+dnU+fG5fz8/AAAAQEBlkSGiIicE5MSIiJySl9//bXV4y1btkChUKBz584AgNtvvx1XrlzBoUOHrOpt3rwZQUFBaNeuHQAgLi4O3333HTIyMhqm4UREVGMcvkVERA3uxIkT0Ol0NuVRUVGWv3/44QckJycjPj4eR48exbvvvothw4ahdevWAOSJ6itXrsQ///lPTJs2DU2aNMGmTZuwd+9evPLKK5abMf7zn//E999/j8TEREyZMgW33XYbrl69it27d+P1119vkP0lIqLKMSkhIqIG969//avC8h9//NHy92uvvYbly5fjs88+g1qtxqhRoyxX4wIAT09PfPrpp3jttdfw+uuvo7CwEOHh4Vi4cCGGDh1qqRcWFoa1a9di0aJFeOONN1BUVIQmTZqgf//+9beDRERUI5IQQji6EURERGbr16/H888/j2+++YZ3fSci+ovgnBIiIiIiInIoJiVERERERORQHL5FREREREQOxZ4SIiIiIiJyKCYlRERERETkUExKiIiIiIjIoZiUEBERERGRQzEpISIiIiIih2JSQkREREREDvX/04durkyHYM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 936x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "# summarize history for loss:\n",
    "plt.plot(history.history['loss'], color='blue', label='train')\n",
    "plt.plot(history.history['val_loss'], color='blue', alpha=0.4, label='validation')\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Cost', fontsize=16)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.title('Average Loss During Training', fontsize=18)\n",
    "#plt.xticks(range(0,epochs))\n",
    "plt.legend(loc='upper right', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
